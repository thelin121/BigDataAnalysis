{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Full text search and keyword association analysis\n",
    "\n",
    "全文檢索與關聯分析"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load preprocessed news dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('PTT_news_preprocessed.csv',sep='|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>date</th>\n",
       "      <th>category</th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>summary</th>\n",
       "      <th>top_key_freq</th>\n",
       "      <th>tokens</th>\n",
       "      <th>tokens_v2</th>\n",
       "      <th>entities</th>\n",
       "      <th>token_pos</th>\n",
       "      <th>link</th>\n",
       "      <th>photo_link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Stock_04-16_1</td>\n",
       "      <td>2025-04-16</td>\n",
       "      <td>學術股市</td>\n",
       "      <td>[新聞] 日媒：台積電將敲定面板級封裝規格 先從</td>\n",
       "      <td>原文標題：日媒：台積電將敲定面板級封裝規格 先從較小尺寸開始原文連結：發布時間：2025-0...</td>\n",
       "      <td>暫無</td>\n",
       "      <td>暫無</td>\n",
       "      <td>[('台積電', 5), ('原文', 3), ('技術', 3), ('日媒', 2), ...</td>\n",
       "      <td>['原文', '標題', '：', '日媒', '：', '台積電', '將', '敲定',...</td>\n",
       "      <td>['原文', '標題', '日媒', '台積電', '面板級', '規格', '尺寸', '...</td>\n",
       "      <td>[NerToken(word='日媒', ner='NORP', idx=(5, 7)), ...</td>\n",
       "      <td>[('原文', 'Na'), ('標題', 'Na'), ('：', 'COLONCATEG...</td>\n",
       "      <td>https://www.ptt.cc/bbs/Stock/M.1744794518.A.3D...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         item_id        date category                     title  \\\n",
       "0  Stock_04-16_1  2025-04-16     學術股市  [新聞] 日媒：台積電將敲定面板級封裝規格 先從   \n",
       "\n",
       "                                             content sentiment summary  \\\n",
       "0  原文標題：日媒：台積電將敲定面板級封裝規格 先從較小尺寸開始原文連結：發布時間：2025-0...        暫無      暫無   \n",
       "\n",
       "                                        top_key_freq  \\\n",
       "0  [('台積電', 5), ('原文', 3), ('技術', 3), ('日媒', 2), ...   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  ['原文', '標題', '：', '日媒', '：', '台積電', '將', '敲定',...   \n",
       "\n",
       "                                           tokens_v2  \\\n",
       "0  ['原文', '標題', '日媒', '台積電', '面板級', '規格', '尺寸', '...   \n",
       "\n",
       "                                            entities  \\\n",
       "0  [NerToken(word='日媒', ner='NORP', idx=(5, 7)), ...   \n",
       "\n",
       "                                           token_pos  \\\n",
       "0  [('原文', 'Na'), ('標題', 'Na'), ('：', 'COLONCATEG...   \n",
       "\n",
       "                                                link  photo_link  \n",
       "0  https://www.ptt.cc/bbs/Stock/M.1744794518.A.3D...         NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter data by searching keywords from \"content\" column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \"in\" is very powerful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'原文標題：日媒：台積電將敲定面板級封裝規格 先從較小尺寸開始原文連結：發布時間：2025-04-15 14:19記者署名：劉忠勇原文內容：日媒報導，台積電（2330）即將敲定「面板級」先進封裝技術規格，預定最快2027年開始小量試產。據報導，台積電新封裝技術的第一代版本，將採用300x300 mm的方形基板，比先前試做的510×515 mm小得多，但相較於傳統的圓形晶圓可用面積更大。台積電為了嚴格控管品質，決定先採用略小的基板。為加快開發進度，台積電正在桃園興建試產線，目標是在2027年左右開始小量試產。。心得/評論：--南茂哥四年投資友達 資產快腰斬 大獲全勝啦！有夠慘的不少小白推文說很棒喔！真是害死不少人第一 群創沒技術第二 群創股本大 如真貢獻也佔比不到營收5%產能kobe:轉型半導體值得投資'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.content[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qk = '台積電'\n",
    "text = df.content[0]\n",
    "qk in text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qk = '居家自主健康管理'\n",
    "text = df.content[0]\n",
    "qk in text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qk = '顧立雄'\n",
    "text = df.content[0]\n",
    "qk in text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qk = '2330'\n",
    "text = df.content[0]\n",
    "qk in text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### all() any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_keywords = ['台積電','2330']\n",
    "text = df.content[0]\n",
    "all((qk in text) for qk in user_keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_keywords = ['肺炎疫情全球延燒','居家自主健康管理']\n",
    "text = df.content[0]\n",
    "any((qk in text) for qk in user_keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_keywords = ['烏克蘭戰爭','外交部']\n",
    "text = df.content[0]\n",
    "any((qk in text) for qk in user_keywords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using apply() and lambda function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      False\n",
       "1       True\n",
       "2      False\n",
       "3      False\n",
       "4      False\n",
       "       ...  \n",
       "263    False\n",
       "264    False\n",
       "265    False\n",
       "266    False\n",
       "267    False\n",
       "Name: content, Length: 268, dtype: bool"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use apply() and lambda function\n",
    "user_keywords = ['川普','命令']\n",
    "df.content.apply(lambda text: all((qk in text) for qk in user_keywords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter data using the following function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "# Searching keywords from \"content\" column\n",
    "# Here this function uses df.content column, while filter_dataFrame() uses df.tokens_v2\n",
    "def filter_dataFrame_fullText(user_keywords, cond, cate, weeks):\n",
    "\n",
    "    # end date: the date of the latest record of news\n",
    "    end_date = df.date.max()\n",
    "    \n",
    "    # start date\n",
    "    start_date = (datetime.strptime(end_date, '%Y-%m-%d').date() - timedelta(weeks=weeks)).strftime('%Y-%m-%d')\n",
    "\n",
    "    # (1) proceed filtering: a duration of a period of time\n",
    "    # 期間條件\n",
    "    period_condition = (df.date >= start_date) & (df.date <= end_date) \n",
    "    \n",
    "    # (2) proceed filtering: news category\n",
    "    # 新聞類別條件\n",
    "    if (cate == \"全部\"):\n",
    "        condition = period_condition  # \"全部\"類別不必過濾新聞種類\n",
    "    else:\n",
    "        # category新聞類別條件\n",
    "        condition = period_condition & (df.category == cate)\n",
    "\n",
    "    # (3) proceed filtering: keywords \n",
    "    # and or 條件\n",
    "    if (cond == 'and'):\n",
    "        # query keywords condition使用者輸入關鍵字條件and\n",
    "        condition = condition & df.content.apply(lambda text: all((qk in text) for qk in user_keywords)) #寫法:all()\n",
    "    elif (cond == 'or'):\n",
    "        # query keywords condition使用者輸入關鍵字條件\n",
    "        condition = condition & df.content.apply(lambda text: any((qk in text) for qk in user_keywords)) #寫法:any()\n",
    "    # condiction is a list of True or False boolean value\n",
    "    df_query = df[condition]\n",
    "\n",
    "    return df_query\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Searching keywords from \"content\" column\n",
    "# Here this function uses df.content column, while filter_dataFrame() uses df.tokens_v2\n",
    "def filter_dataFrame_fullText_v0(user_keywords, cond, cate, weeks):\n",
    "\n",
    "    # end date: the date of the latest record of news\n",
    "    end_date = df.date.max()\n",
    "    \n",
    "    # start date\n",
    "    start_date = (datetime.strptime(end_date, '%Y-%m-%d').date() - timedelta(weeks=weeks)).strftime('%Y-%m-%d')\n",
    "\n",
    "    # proceed filtering\n",
    "    if (cate == \"全部\") & (cond == 'and'):\n",
    "        df_query = df[(df.date >= start_date) & (df.date <= end_date) \n",
    "            & df.content.apply(lambda text: all((qk in text) for qk in user_keywords))]\n",
    "    elif (cate == \"全部\") & (cond == 'or'):\n",
    "        df_query = df[(df['date'] >= start_date) & (df['date'] <= end_date) \n",
    "            & df.content.apply(lambda text: any((qk in text) for qk in user_keywords))]\n",
    "    elif (cond == 'and'):\n",
    "        df_query = df[(df.category == cate) \n",
    "            & (df.date >= start_date) & (df.date <= end_date) \n",
    "            & df.content.apply(lambda text: all((qk in text) for qk in user_keywords))]\n",
    "    elif (cond == 'or'):\n",
    "        df_query = df[(df.category == cate) \n",
    "            & (df['date'] >= start_date) & (df['date'] <= end_date) \n",
    "            & df.content.apply(lambda text: any((qk in text) for qk in user_keywords))]\n",
    "\n",
    "    return df_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 14)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_keywords = ['川普','外交部']\n",
    "cond='and'\n",
    "cate='全部'\n",
    "weeks=2\n",
    "\n",
    "df_query = filter_dataFrame_fullText(user_keywords, cond, cate,weeks)\n",
    "df_query.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(43, 14)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_keywords = ['川普']\n",
    "cond='and'\n",
    "cate='全部'\n",
    "weeks=2\n",
    "\n",
    "df_query = filter_dataFrame_fullText(user_keywords, cond, cate,weeks)\n",
    "df_query.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "# Get news title, category, and link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_keywords = ['川普','外交部']\n",
    "cond='and'\n",
    "cate='全部'\n",
    "weeks=2\n",
    "df_query = filter_dataFrame_fullText(user_keywords, cond, cate, weeks)\n",
    "len(df_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>date</th>\n",
       "      <th>category</th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>summary</th>\n",
       "      <th>top_key_freq</th>\n",
       "      <th>tokens</th>\n",
       "      <th>tokens_v2</th>\n",
       "      <th>entities</th>\n",
       "      <th>token_pos</th>\n",
       "      <th>link</th>\n",
       "      <th>photo_link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>Military_04-16_13</td>\n",
       "      <td>2025-04-16</td>\n",
       "      <td>軍事</td>\n",
       "      <td>[情報] 烏軍官方殲敵統計&amp;情報數則 (25/4/16)</td>\n",
       "      <td>[統計部分]自22/2/24到25/4/16以來的俄軍損失統計人員：約936210名 (+1...</td>\n",
       "      <td>暫無</td>\n",
       "      <td>暫無</td>\n",
       "      <td>[('烏克蘭', 7), ('俄軍', 5), ('俄羅斯', 5), ('系統', 4),...</td>\n",
       "      <td>['[', '統計', '部分', ']', '自', '22/2/24', '到', '2...</td>\n",
       "      <td>['統計', '俄軍', '統計', '人員', '定翼機', '旋翼機', '坦克', '...</td>\n",
       "      <td>[NerToken(word='俄軍', ner='ORG', idx=(25, 27)),...</td>\n",
       "      <td>[('[', 'PARENTHESISCATEGORY'), ('統計', 'Na'), (...</td>\n",
       "      <td>https://www.ptt.cc/bbs/Military/M.1744794058.A...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               item_id        date category                         title  \\\n",
       "225  Military_04-16_13  2025-04-16       軍事  [情報] 烏軍官方殲敵統計&情報數則 (25/4/16)   \n",
       "\n",
       "                                               content sentiment summary  \\\n",
       "225  [統計部分]自22/2/24到25/4/16以來的俄軍損失統計人員：約936210名 (+1...        暫無      暫無   \n",
       "\n",
       "                                          top_key_freq  \\\n",
       "225  [('烏克蘭', 7), ('俄軍', 5), ('俄羅斯', 5), ('系統', 4),...   \n",
       "\n",
       "                                                tokens  \\\n",
       "225  ['[', '統計', '部分', ']', '自', '22/2/24', '到', '2...   \n",
       "\n",
       "                                             tokens_v2  \\\n",
       "225  ['統計', '俄軍', '統計', '人員', '定翼機', '旋翼機', '坦克', '...   \n",
       "\n",
       "                                              entities  \\\n",
       "225  [NerToken(word='俄軍', ner='ORG', idx=(25, 27)),...   \n",
       "\n",
       "                                             token_pos  \\\n",
       "225  [('[', 'PARENTHESISCATEGORY'), ('統計', 'Na'), (...   \n",
       "\n",
       "                                                  link  photo_link  \n",
       "225  https://www.ptt.cc/bbs/Military/M.1744794058.A...         NaN  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "軍事\n",
      "[情報] 烏軍官方殲敵統計&情報數則 (25/4/16)\n",
      "https://www.ptt.cc/bbs/Military/M.1744794058.A.BE5.html\n"
     ]
    }
   ],
   "source": [
    "for i in range(min(3, len(df_query))):  # 最多印出3筆\n",
    "    print(i)\n",
    "    print(df_query.iloc[i]['category'])\n",
    "    print(df_query.iloc[i]['title'])\n",
    "    print(df_query.iloc[i]['link'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>date</th>\n",
       "      <th>category</th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>summary</th>\n",
       "      <th>top_key_freq</th>\n",
       "      <th>tokens</th>\n",
       "      <th>tokens_v2</th>\n",
       "      <th>entities</th>\n",
       "      <th>token_pos</th>\n",
       "      <th>link</th>\n",
       "      <th>photo_link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>Military_04-16_13</td>\n",
       "      <td>2025-04-16</td>\n",
       "      <td>軍事</td>\n",
       "      <td>[情報] 烏軍官方殲敵統計&amp;情報數則 (25/4/16)</td>\n",
       "      <td>[統計部分]自22/2/24到25/4/16以來的俄軍損失統計人員：約936210名 (+1...</td>\n",
       "      <td>暫無</td>\n",
       "      <td>暫無</td>\n",
       "      <td>[('烏克蘭', 7), ('俄軍', 5), ('俄羅斯', 5), ('系統', 4),...</td>\n",
       "      <td>['[', '統計', '部分', ']', '自', '22/2/24', '到', '2...</td>\n",
       "      <td>['統計', '俄軍', '統計', '人員', '定翼機', '旋翼機', '坦克', '...</td>\n",
       "      <td>[NerToken(word='俄軍', ner='ORG', idx=(25, 27)),...</td>\n",
       "      <td>[('[', 'PARENTHESISCATEGORY'), ('統計', 'Na'), (...</td>\n",
       "      <td>https://www.ptt.cc/bbs/Military/M.1744794058.A...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               item_id        date category                         title  \\\n",
       "225  Military_04-16_13  2025-04-16       軍事  [情報] 烏軍官方殲敵統計&情報數則 (25/4/16)   \n",
       "\n",
       "                                               content sentiment summary  \\\n",
       "225  [統計部分]自22/2/24到25/4/16以來的俄軍損失統計人員：約936210名 (+1...        暫無      暫無   \n",
       "\n",
       "                                          top_key_freq  \\\n",
       "225  [('烏克蘭', 7), ('俄軍', 5), ('俄羅斯', 5), ('系統', 4),...   \n",
       "\n",
       "                                                tokens  \\\n",
       "225  ['[', '統計', '部分', ']', '自', '22/2/24', '到', '2...   \n",
       "\n",
       "                                             tokens_v2  \\\n",
       "225  ['統計', '俄軍', '統計', '人員', '定翼機', '旋翼機', '坦克', '...   \n",
       "\n",
       "                                              entities  \\\n",
       "225  [NerToken(word='俄軍', ner='ORG', idx=(25, 27)),...   \n",
       "\n",
       "                                             token_pos  \\\n",
       "225  [('[', 'PARENTHESISCATEGORY'), ('統計', 'Na'), (...   \n",
       "\n",
       "                                                  link  photo_link  \n",
       "225  https://www.ptt.cc/bbs/Military/M.1744794058.A...         NaN  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_query.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All-in-one function to return category, title, link, and photo_link\n",
    "\n",
    "\"photo_link\" will be use in the next app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_keywords = ['川普','中國']\n",
    "cond='and'\n",
    "cate='全部'\n",
    "weeks=2\n",
    "df_query = filter_dataFrame_fullText(user_keywords, cond, cate, weeks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get titles and links from k pieces of news \n",
    "def get_title_link_topk(df_query, k=5):\n",
    "    items = []\n",
    "    for i in range( len(df_query[0:k]) ): # show only 5 articles\n",
    "        category = df_query.iloc[i]['category']\n",
    "        title = df_query.iloc[i]['title']\n",
    "        link = df_query.iloc[i]['link']\n",
    "        photo_link = df_query.iloc[i]['photo_link']\n",
    "        # if photo_link value is NaN, replace it with empty string \n",
    "        if pd.isna(photo_link):\n",
    "            photo_link='' # 若沒圖片，就設定為空字串，在前端網頁解讀json格式時才不會錯誤\n",
    "        \n",
    "        item_info = {\n",
    "            'category': category, \n",
    "            'title': title, \n",
    "            'link': link, \n",
    "            'photo_link': photo_link\n",
    "        }\n",
    "\n",
    "        items.append(item_info)\n",
    "    return items "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'category': '學術股市',\n",
       "  'title': 'Re: [新聞] 川普傳打算以關稅談判孤立中國 可能要各',\n",
       "  'link': 'https://www.ptt.cc/bbs/Stock/M.1744794681.A.85D.html',\n",
       "  'photo_link': ''},\n",
       " {'category': '學術股市',\n",
       "  'title': '[新聞] 川普大讚「關稅政策」有效！\\u3000發文激讚',\n",
       "  'link': 'https://www.ptt.cc/bbs/Stock/M.1744794813.A.004.html',\n",
       "  'photo_link': ''},\n",
       " {'category': '學術股市',\n",
       "  'title': 'Re: [請益] 中國繼續擺爛是不是要害慘全世界？',\n",
       "  'link': 'https://www.ptt.cc/bbs/Stock/M.1744795403.A.4DD.html',\n",
       "  'photo_link': ''}]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_title_link_topk(df_query, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some photo_links are \"NaN\". \n",
    "\n",
    "If the photo_link value is 'nan', it will be a problem when converted to json format on Django!\n",
    "\n",
    "    \"NaN\" cannot be converted to a JSON string. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(nan)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_query.iloc[0]['photo_link']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the photo_link is NaN or not and replace it with empty string\n",
    "    How to do?\n",
    "    You can test a variable is \"NaN\" or not by using pd, np or math."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It's pd.isna  : True\n",
      "It's np.isnan  : True\n",
      "It's math.isnan : True\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "# we can use pandas, numpy or math to check if photo_link is NaN\n",
    "x = float(\"nan\")\n",
    "\n",
    "print(f\"It's pd.isna  : {pd.isna(x)}\")\n",
    "print(f\"It's np.isnan  : {np.isnan(x)}\")\n",
    "print(f\"It's math.isnan : {math.isnan(x)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(nan)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_query.iloc[0]['photo_link']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "photo_link = df_query.iloc[0]['photo_link']\n",
    "# if photo_link value is NaN, replace it with empty string \n",
    "if pd.isna(photo_link):\n",
    "    photo_link='' # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "photo_link"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "# Find some related keywords\n",
    "\n",
    "    Find related words from the top_key_freq column\n",
    "    相關詞有哪一些? 找出各篇文章的topk關鍵詞?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All-in-one function: Get related keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "# 相關詞有哪一些?找出各篇文章的topk關鍵詞加以彙整計算\n",
    "# 不能用 \"get_related_keys\"當函數名稱，因為這是Django系統用的名稱\n",
    "def get_related_words(df_query):\n",
    "    counter=Counter() # this counter is for all articles\n",
    "    for idx in range(len(df_query)):\n",
    "        pair_dict = dict(eval(df_query.iloc[idx].top_key_freq))\n",
    "        counter += Counter(pair_dict)\n",
    "    return counter.most_common(20) #return list format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This version is for reference\n",
    "def get_related_words_v0(df_query):\n",
    "    all_pairs={}\n",
    "    for idx in range(len(df_query)):\n",
    "        row = df_query.iloc[idx].top_key_freq\n",
    "        pairs = eval(row)\n",
    "        for pair in pairs:\n",
    "            w,f = pair\n",
    "            if w in all_pairs:\n",
    "                all_pairs[w]+= f\n",
    "            else:\n",
    "                all_pairs[w] = f\n",
    "\n",
    "    counter = Counter(all_pairs)\n",
    "    return counter.most_common(20) #return list format\n",
    "    #return dict(counter.most_common(20)) #return dict format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_keywords = ['川普','中國']\n",
    "cond='and'\n",
    "cate='全部'\n",
    "weeks=2\n",
    "df_query = filter_dataFrame_fullText(user_keywords, cond, cate, weeks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25, 14)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_query.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('中國', 200),\n",
       " ('美國', 184),\n",
       " ('關稅', 97),\n",
       " ('川普', 77),\n",
       " ('經濟', 65),\n",
       " ('台灣', 48),\n",
       " ('政府', 40),\n",
       " ('國家', 37),\n",
       " ('貿易', 29),\n",
       " ('政策', 24),\n",
       " ('產業', 20),\n",
       " ('風險', 20),\n",
       " ('晶片', 19),\n",
       " ('市場', 19),\n",
       " ('原文', 17),\n",
       " ('歐盟', 17),\n",
       " ('世界', 16),\n",
       " ('總統', 14),\n",
       " ('商品', 14),\n",
       " ('歐洲', 14)]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_related_words(df_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# get_related_words_v1(df_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Step by step demonstration (do it yourself)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_keywords = ['川普','中國']\n",
    "cond='and'\n",
    "cate='全部'\n",
    "weeks=2\n",
    "df_query = filter_dataFrame_fullText(user_keywords, cond, cate, weeks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>date</th>\n",
       "      <th>category</th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>summary</th>\n",
       "      <th>top_key_freq</th>\n",
       "      <th>tokens</th>\n",
       "      <th>tokens_v2</th>\n",
       "      <th>entities</th>\n",
       "      <th>token_pos</th>\n",
       "      <th>link</th>\n",
       "      <th>photo_link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stock_04-16_2</td>\n",
       "      <td>2025-04-16</td>\n",
       "      <td>學術股市</td>\n",
       "      <td>Re: [新聞] 川普傳打算以關稅談判孤立中國 可能要各</td>\n",
       "      <td>從廣場協議看2018美中貿易戰 的升級版，及這次的關稅事件，廣場協議的主因也是貿易逆差跟美元...</td>\n",
       "      <td>暫無</td>\n",
       "      <td>暫無</td>\n",
       "      <td>[('中國', 36), ('美國', 30), ('國家', 21), ('技術', 13...</td>\n",
       "      <td>['從', '廣場', '協議', '看', '2018', '美中', '貿易戰 ', '...</td>\n",
       "      <td>['廣場', '協議', '美中', '貿易戰 ', '升級版', '關稅', '事件', ...</td>\n",
       "      <td>[NerToken(word='美國鋼鐵', ner='ORG', idx=(57, 61)...</td>\n",
       "      <td>[('從', 'P'), ('廣場', 'Nc'), ('協議', 'Na'), ('看',...</td>\n",
       "      <td>https://www.ptt.cc/bbs/Stock/M.1744794681.A.85...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Stock_04-16_3</td>\n",
       "      <td>2025-04-16</td>\n",
       "      <td>學術股市</td>\n",
       "      <td>[新聞] 川普大讚「關稅政策」有效！　發文激讚</td>\n",
       "      <td>川普大讚「關稅政策」有效！　發文激讚：美國通膨下降了ETTODAY2025年04月16日 1...</td>\n",
       "      <td>暫無</td>\n",
       "      <td>暫無</td>\n",
       "      <td>[('關稅', 9), ('川普', 6), ('美國', 4), ('政策', 3), (...</td>\n",
       "      <td>['川普', '大讚', '「', '關稅', '政策', '」', '有效', '！', ...</td>\n",
       "      <td>['川普', '關稅', '政策', '美國', '通膨', '記者', '吳美依', '美...</td>\n",
       "      <td>[NerToken(word='川', ner='PERSON', idx=(0, 1)),...</td>\n",
       "      <td>[('川普', 'Nb'), ('大讚', 'VC'), ('「', 'PARENTHESI...</td>\n",
       "      <td>https://www.ptt.cc/bbs/Stock/M.1744794813.A.00...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         item_id        date category                         title  \\\n",
       "1  Stock_04-16_2  2025-04-16     學術股市  Re: [新聞] 川普傳打算以關稅談判孤立中國 可能要各   \n",
       "2  Stock_04-16_3  2025-04-16     學術股市       [新聞] 川普大讚「關稅政策」有效！　發文激讚   \n",
       "\n",
       "                                             content sentiment summary  \\\n",
       "1  從廣場協議看2018美中貿易戰 的升級版，及這次的關稅事件，廣場協議的主因也是貿易逆差跟美元...        暫無      暫無   \n",
       "2  川普大讚「關稅政策」有效！　發文激讚：美國通膨下降了ETTODAY2025年04月16日 1...        暫無      暫無   \n",
       "\n",
       "                                        top_key_freq  \\\n",
       "1  [('中國', 36), ('美國', 30), ('國家', 21), ('技術', 13...   \n",
       "2  [('關稅', 9), ('川普', 6), ('美國', 4), ('政策', 3), (...   \n",
       "\n",
       "                                              tokens  \\\n",
       "1  ['從', '廣場', '協議', '看', '2018', '美中', '貿易戰 ', '...   \n",
       "2  ['川普', '大讚', '「', '關稅', '政策', '」', '有效', '！', ...   \n",
       "\n",
       "                                           tokens_v2  \\\n",
       "1  ['廣場', '協議', '美中', '貿易戰 ', '升級版', '關稅', '事件', ...   \n",
       "2  ['川普', '關稅', '政策', '美國', '通膨', '記者', '吳美依', '美...   \n",
       "\n",
       "                                            entities  \\\n",
       "1  [NerToken(word='美國鋼鐵', ner='ORG', idx=(57, 61)...   \n",
       "2  [NerToken(word='川', ner='PERSON', idx=(0, 1)),...   \n",
       "\n",
       "                                           token_pos  \\\n",
       "1  [('從', 'P'), ('廣場', 'Nc'), ('協議', 'Na'), ('看',...   \n",
       "2  [('川普', 'Nb'), ('大讚', 'VC'), ('「', 'PARENTHESI...   \n",
       "\n",
       "                                                link  photo_link  \n",
       "1  https://www.ptt.cc/bbs/Stock/M.1744794681.A.85...         NaN  \n",
       "2  https://www.ptt.cc/bbs/Stock/M.1744794813.A.00...         NaN  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_query.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1      [('中國', 36), ('美國', 30), ('國家', 21), ('技術', 13...\n",
       "2      [('關稅', 9), ('川普', 6), ('美國', 4), ('政策', 3), (...\n",
       "4      [('中國', 9), ('經濟', 3), ('內需', 3), ('川普', 2), (...\n",
       "5      [('美國', 3), ('中國', 3), ('台灣', 2), ('瑞昱', 2), (...\n",
       "6      [('中國', 21), ('經濟', 11), ('美國', 9), ('企業', 6),...\n",
       "7      [('中國', 5), ('原文', 3), ('美國', 2), ('台灣', 2), (...\n",
       "18     [('中國', 21), ('關稅', 19), ('美國', 13), ('魷魚', 9)...\n",
       "23     [('經濟', 32), ('美國', 19), ('風險', 18), ('川普', 14...\n",
       "24     [('總量', 4), ('貨運', 2), ('數據', 2), ('公司', 2), (...\n",
       "25     [('台灣', 8), ('中國', 7), ('美國', 5), ('關稅', 4), (...\n",
       "27     [('中國', 21), ('歐洲', 13), ('關稅', 8), ('經濟', 6),...\n",
       "28     [('中國', 15), ('美國', 10), ('台灣', 7), ('川爺', 5),...\n",
       "29     [('關稅', 10), ('台積電', 8), ('時間', 7), ('川普', 6),...\n",
       "31     [('中國', 8), ('商務部', 7), ('貿易', 7), ('李成鋼', 6),...\n",
       "39     [('中國', 14), ('美國', 14), ('關稅', 6), ('川普', 6),...\n",
       "40     [('預期', 5), ('中國', 5), ('訂單', 4), ('關稅', 4), (...\n",
       "45     [('美國', 3), ('川普', 3), ('歐盟', 2), ('關稅', 2), (...\n",
       "46     [('美國', 9), ('關稅', 8), ('意義', 5), ('國家', 4), (...\n",
       "48     [('台灣', 10), ('晶片', 6), ('翁履中', 5), ('川普', 4),...\n",
       "51     [('美國', 10), ('關稅', 8), ('政府', 8), ('林伯豐', 7),...\n",
       "89     [('中國', 14), ('美國', 12), ('情況', 4), ('血條', 3),...\n",
       "99     [('中國', 8), ('大陸', 4), ('美國', 3), ('台灣', 3), (...\n",
       "217    [('川普', 21), ('政府', 17), ('伊朗', 13), ('美國', 12...\n",
       "219    [('官員', 5), ('歐盟', 3), ('美國', 3), ('中國', 3), (...\n",
       "241    [('計畫', 3), ('非洲', 3), ('川普', 2), ('政府', 2), (...\n",
       "Name: top_key_freq, dtype: object"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_query.top_key_freq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From the word_freq pairs, we sum frequency for each word\n",
    "\n",
    "    How? \n",
    "    The best way is to use dict. Here is a simple example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('陳時中', 7), ('解封', 5), ('疫情', 4), ('檢疫期', 3)]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[('陳時中', 7), ('解封', 5), ('疫情', 4), ('檢疫期', 3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'陳時中': 7, '解封': 5, '疫情': 4, '檢疫期': 3}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "{'陳時中': 7,\n",
    " '解封': 5,\n",
    " '疫情': 10,\n",
    " '檢疫期': 3}\n",
    "\n",
    " (key, value) key can't be duplicated.鍵值不能重複，轉成dict時不處理重複的，會被丟棄\n",
    "'''\n",
    "\n",
    "dict([('陳時中', 7), ('解封', 5), ('疫情', 4), ('檢疫期', 3)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'王金平': 2, '吳敦義': 5}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  (key, value) key can't be duplicated.鍵值不能重複，轉成dict時不處理重複的，會被丟棄\n",
    "dict([('王金平', 2), ('吳敦義', 7), ('吳敦義', 5)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "c1 = Counter(dict([('陳時中', 7), ('解封', 5), ('疫情', 4), ('檢疫期', 3)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'陳時中': 7, '解封': 5, '疫情': 4, '檢疫期': 3})"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "c2 = Counter(dict([('馬英九', 2), ('陳時中', 7), ('蔡英文', 20)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'蔡英文': 20, '陳時中': 7, '馬英九': 2})"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'蔡英文': 20, '陳時中': 14, '解封': 5, '疫情': 4, '檢疫期': 3, '馬英九': 2})"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c1+c2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"[('中國', 36), ('美國', 30), ('國家', 21), ('技術', 13), ('位置', 12), ('科技', 9), ('關稅', 8), ('產業', 8), ('晶片', 8), ('總統', 8), ('台灣', 8), ('程度', 8), ('世界', 7), ('政策', 7), ('經濟', 7), ('產品', 6), ('廣場', 5), ('政府', 5), ('傷害', 5), ('局勢', 5)]\""
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Now we can start to cout frequency from our word_freq pairs\n",
    "df_query.iloc[0].top_key_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'中國': 36,\n",
       " '美國': 30,\n",
       " '國家': 21,\n",
       " '技術': 13,\n",
       " '位置': 12,\n",
       " '科技': 9,\n",
       " '關稅': 8,\n",
       " '產業': 8,\n",
       " '晶片': 8,\n",
       " '總統': 8,\n",
       " '台灣': 8,\n",
       " '程度': 8,\n",
       " '世界': 7,\n",
       " '政策': 7,\n",
       " '經濟': 7,\n",
       " '產品': 6,\n",
       " '廣場': 5,\n",
       " '政府': 5,\n",
       " '傷害': 5,\n",
       " '局勢': 5}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert to dictionary\n",
    "dict(eval(df_query.iloc[0].top_key_freq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('中國', 36),\n",
       " ('美國', 30),\n",
       " ('國家', 21),\n",
       " ('技術', 13),\n",
       " ('位置', 12),\n",
       " ('科技', 9),\n",
       " ('關稅', 8),\n",
       " ('產業', 8),\n",
       " ('晶片', 8),\n",
       " ('總統', 8)]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c1 = Counter(dict(eval(df_query.iloc[0].top_key_freq)))\n",
    "c1.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('關稅', 9),\n",
       " ('川普', 6),\n",
       " ('美國', 4),\n",
       " ('政策', 3),\n",
       " ('記者', 2),\n",
       " ('總統', 2),\n",
       " ('發文', 2),\n",
       " ('全球', 2),\n",
       " ('產業', 2),\n",
       " ('通膨', 1)]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c2 = Counter(dict(eval(df_query.iloc[1].top_key_freq)))\n",
    "c2.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('中國', 36),\n",
       " ('美國', 34),\n",
       " ('國家', 21),\n",
       " ('關稅', 17),\n",
       " ('技術', 13),\n",
       " ('位置', 12),\n",
       " ('產業', 10),\n",
       " ('總統', 10),\n",
       " ('政策', 10),\n",
       " ('科技', 9)]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter = c1+c2\n",
    "counter.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Advance operation for reference\n",
    "# Using the itertools.groupby approach, you are summing the sorted groups based on first tuple elements.\n",
    "\n",
    "# from itertools import groupby\n",
    "# from operator import itemgetter\n",
    "\n",
    "# my_list = [('a',2),('a',3),('b',3),('c',2),('b',4)]\n",
    "# first = itemgetter(0)\n",
    "# sums = [(k, sum(item[1] for item in tups_to_sum))\n",
    "#         for k, tups_to_sum in groupby(sorted(my_list, key=first), key=first)]\n",
    "# Outputs:\n",
    "\n",
    "# [('a', 5), ('b', 7), ('c', 2)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare wordcloud data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    textSizeMin = 10 # new_min\n",
    "    textSizeMax = 80 # new_max\n",
    "    新餅多大: 80-10 = 70\n",
    "\n",
    "    {'text': '黃重凱', 'size': 24}   ==> 80\n",
    "     {'text': '吳釗燮', 'size': 4}   ==> 10\n",
    "     舊餅多大: 24-4 = 20\n",
    "\n",
    "     (24-4) / (24-4)  * ( 80-10  )  + 10  ==> 80\n",
    "     (13-4) / (24-4)  * ( 80-10  )  + 10  ==> 41\n",
    "     ...\n",
    "     ...\n",
    "     (4-4) / (24-4)  * ( 80-10  )  + 10  ==> 10\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Min-Max Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://image.slidesharecdn.com/tcdsp17-featureengineering-extendedversion-170719211326/95/feature-engineering-getting-most-out-of-data-for-predictive-models-tdc-2017-30-638.jpg?cb=1500581962\" width=\"550\">\n",
    "\n",
    "<img src=\"https://chrisalbon.com/images/machine_learning_flashcards/MinMax_Scaling_print.png\" width=\"550\">\n",
    "\n",
    "\n",
    "<img src='https://www.researchgate.net/publication/282541174/figure/fig1/AS:307388692353061@1450298583749/Min-max-method-of-normalization.png' width=\"550\">\n",
    "\n",
    "<img src='https://t4tutorials.com/wp-content/uploads/2019/09/Min-Max-Normalization-Equation-Pythone-Matlab.png' width=\"550\">\n",
    "\n",
    "<img src='scale_formula.jpg' width=\"550\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get related keywords by counting the top keywords of each news.\n",
    "# Notice:  do not name function as  \"get_related_keys\",\n",
    "# because this name is used in Django\n",
    "def get_related_word_clouddata(df_query):\n",
    "\n",
    "    # (1) Get wf_pairs by calling get_related_words().\n",
    "    wf_pairs = get_related_words(df_query)\n",
    "    \n",
    "    # (2) cloud chart data\n",
    "    # the minimum and maximum frequency of top words\n",
    "    min_ = wf_pairs[-1][1]  # the last line is smaller\n",
    "    max_ = wf_pairs[0][1]\n",
    "    # text size based on the value of word frequency for drawing cloud chart\n",
    "    # Scaling frequency value into an interval of from 20 to 120.\n",
    "    textSizeMin = 20 # 最小字\n",
    "    textSizeMax = 120 # 最大字\n",
    "    \n",
    "    # if all frequences are the same, \"divided by zero\" exception will arise.\n",
    "    # In the following case, exception will arise.\n",
    "    # We must deal with this.\n",
    "    # [('AA', 1), ('BB', 1), ('CC', 1)]\n",
    "    # Instead of (max_-min_), we use len(wf_pairs) as divisor.\n",
    "    # every word size is 1 / len(wf_pairs) \n",
    "    # 當每個字的頻率都一樣時，讓每個字的高度大小都一樣，分子是1，分母是字數==>均分\n",
    "    \n",
    "    # 排除分母為0的情況\n",
    "    # 這裡的min_是最小值，max_是最大值，這兩個值是頻率的大小\n",
    "    if (min_ != max_):\n",
    "        max_min_range = max_ - min_\n",
    "\n",
    "    else:\n",
    "        max_min_range = len(wf_pairs) # 關鍵詞的數量: 20個\n",
    "        min_ = min_ - 1 # every size is 1 / len(wf_pairs)\n",
    "    \n",
    "    # word cloud chart data using proportional scaling\n",
    "    # 排除分母為0的情況\n",
    "    clouddata = [{'text':w, 'size':int(textSizeMin + (f - min_)/max_min_range * (textSizeMax-textSizeMin))} for w, f in wf_pairs]\n",
    "\n",
    "    # 可能分母為0的情況\n",
    "    # clouddata = [{'text': w, 'size': int(textSizeMin + (f - min_) / (max_ - min_) * (textSizeMax - textSizeMin))} for w, f in wf_pairs]\n",
    "\n",
    "    return   wf_pairs, clouddata "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([('中國', 173),\n",
       "  ('美國', 161),\n",
       "  ('關稅', 108),\n",
       "  ('經濟', 65),\n",
       "  ('川普', 59),\n",
       "  ('台灣', 44),\n",
       "  ('國家', 38),\n",
       "  ('貿易', 29),\n",
       "  ('政策', 26),\n",
       "  ('烏克蘭', 25),\n",
       "  ('歐洲', 24),\n",
       "  ('市場', 22),\n",
       "  ('政府', 21),\n",
       "  ('產業', 19),\n",
       "  ('晶片', 18),\n",
       "  ('風險', 18),\n",
       "  ('俄羅斯', 16),\n",
       "  ('全球', 15),\n",
       "  ('總統', 14),\n",
       "  ('產品', 14)],\n",
       " [{'text': '中國', 'size': 120},\n",
       "  {'text': '美國', 'size': 112},\n",
       "  {'text': '關稅', 'size': 79},\n",
       "  {'text': '經濟', 'size': 52},\n",
       "  {'text': '川普', 'size': 48},\n",
       "  {'text': '台灣', 'size': 38},\n",
       "  {'text': '國家', 'size': 35},\n",
       "  {'text': '貿易', 'size': 29},\n",
       "  {'text': '政策', 'size': 27},\n",
       "  {'text': '烏克蘭', 'size': 26},\n",
       "  {'text': '歐洲', 'size': 26},\n",
       "  {'text': '市場', 'size': 25},\n",
       "  {'text': '政府', 'size': 24},\n",
       "  {'text': '產業', 'size': 23},\n",
       "  {'text': '晶片', 'size': 22},\n",
       "  {'text': '風險', 'size': 22},\n",
       "  {'text': '俄羅斯', 'size': 21},\n",
       "  {'text': '全球', 'size': 20},\n",
       "  {'text': '總統', 'size': 20},\n",
       "  {'text': '產品', 'size': 20}])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_keywords = ['川普','關稅']\n",
    "cond='and'\n",
    "cate='全部'\n",
    "weeks=2\n",
    "df_query = filter_dataFrame_fullText(user_keywords, cond, cate, weeks)\n",
    "\n",
    "get_related_word_clouddata(df_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "# Find paragraphs containing the keywords. \n",
    "\n",
    "    There may be too many related paragraphs, so we display only some of them on our Django website\n",
    "    一一比對文章段落，找出關鍵詞所在的段落"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All-in-one function: Find related paragraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Step1: split paragraphs in text 先將文章切成一個段落一個段落\n",
    "def cut_paragraph(text):\n",
    "    paragraphs = text.split('。')  # 遇到句號就切開 功能有限\n",
    "    #paragraphs = re.split('。', text) # 遇到句號就切開\n",
    "    #paragraphs = re.split('[。！!？?]', text) # 遇到句號(也納入問號、驚嘆號、分號等)就切開\n",
    "    paragraphs = list(filter(None, paragraphs))\n",
    "    return paragraphs\n",
    "\n",
    "\n",
    "import re\n",
    "# Find out all paragraphs where multiple keywords occur.\n",
    "def get_same_para(df_query, user_keywords, cond, k=10):\n",
    "    same_para=[]\n",
    "    for text in df_query.content:\n",
    "        #print(text)\n",
    "        paragraphs = cut_paragraph(text)\n",
    "        for para in paragraphs:\n",
    "            para += \"。\"  # 在每段落文字後面加一個句號。\n",
    "            # 判斷每個段落文字是否包含該關鍵字，and or分開判斷\n",
    "            if cond == 'and':\n",
    "                if all([kw in para for kw in user_keywords]):\n",
    "                    same_para.append(para)  # 符合條件的段落para保存起來\n",
    "            elif cond == 'or':\n",
    "                if any([kw in para for kw in user_keywords]):\n",
    "                    same_para.append(para)  # 符合條件的段落para保存起來\n",
    "    return same_para[0:k]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_keywords = ['川普','關稅','中國']\n",
    "cond='and'\n",
    "cate='全部'\n",
    "weeks=2\n",
    "df_query = filter_dataFrame_fullText(user_keywords, cond, cate, weeks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['」認為，輝達之所以這麼做，是因為他在去年11月5日當選，並且實施了關稅，心得評論：對等關稅4月才實施（除中國加徵至145-245%，其他經濟體暫緩90天剩10%），墨加關稅4月2號才正式實施，三月有的關稅大概就鋼鋁關稅25%，現在就出來吹了，恐怕要看到真實影響數據還要再幾個月吧？--油價是OPEC+的關係吧（？）鮑爾就要軟著陸成功 半途殺出川普搞砸一切，要是川普不這樣搞，可能真的可以軟著陸。',\n",
       " '感覺上你在反串不過中國的確在擺爛，而且早在川普發動關稅戰前就在擺爛中國要經濟轉型、要促進內需這套說法從胡錦濤時代就一直講了講到現在中國的內需還是過低中國加入WTO快25年，幾乎把世界市場吃了一大半結果不僅沒有辦法培養出相應的內需市場反而養出了一個頭重腳輕的怪胎就算今天不是川普發難，遲早也會有其他的美國總統或歐盟政治領袖採取動作川普被人抨擊的並不是針對中國這點，而是手段粗暴欠缺考量，地圖砲朝盟友開習近平的確是在擺爛，比較跟中國差不多人均GDP的國家中國的社會保障、社會安全這塊也是倒數的那就演變成國富民窮的情況民間超額儲蓄 > 儲蓄投入房地產 > 房地產泡沫，資產損失 > 消費更加緊縮中國政府這個時候不僅沒有想辦法去降低人民負擔反而還要加緊集中權力、收攏資源備戰也就是習近平認為現在是東昇西降，是百年難得一遇的戰略機遇他要強化集權、重新集中資源去打一場自認的\"國運之戰\"美國無謀引戰在先，但影響更大的，恐怕會是上述中國的誤判如果關稅戰爛尾還好，經濟就動盪個小半年就是川普個人政治生涯終結，大家事後慢慢修補他造成的破壞如果關稅戰無意觸發了中美之間全面性的對抗，經濟世界大戰後果不堪設想所謂 \"結束所有戰爭的戰爭\" 或 \"一戰定乾坤\" 從來都是妄想這點不管是熱戰、冷戰、經濟戰、科技戰都一樣--。',\n",
       " '原文標題：「中國扛不住245％關稅」大量工廠放長假了！2000萬人慘失業原文連結：發布時間：2025-04-16記者署名：林瑩真原文內容：隨著美國總統川普再度祭出對中高額關稅，中國經濟面臨新一波衝擊。',\n",
       " '川普關稅重擊中國出口，中國企業停產裁員潮蔓延自美方啟動貿易戰以來，中國多數出口導向企業生產計畫紛紛停擺，許多工廠選擇提前放長假，長江三角洲與珠江三角洲地區更出現大規模裁員潮，失業農民工紛紛返鄉，被迫「提前過年」。',\n",
       " '美國總統川普本月9日授權對多國祭出的對等關稅措施暫停實施90天，在這段期間僅課徵10%的關稅，立即生效，但對中國進口商品課徵關稅總稅率提高至145%。',\n",
       " '同樣，在貿易戰中，川普通過對中國加徵關稅，施加壓力，這讓許多美國企業和消費者感受到了一定的短期經濟損失。',\n",
       " '我們來看看川普在說什麼舉例台灣來說中國賣給台灣=>不可以台灣賣給中國=>允許(但中國東西就比你便宜他幹嘛跟你買，他想買的gg晶片美國說不可以)美國賣給台灣=>可以，而且要盡情的消費台灣賣給美國=>可以，但是要加關稅關稅還要你自行吸收不能加價結果就是我們賺的錢變少，花的錢變多然後最後通縮不確定中美貿易戰誰能撐到最後，但在結局出來之前台灣已經死在過程中了而且目前看來在過程中我們還要輸血給美國幫助他撐到最後股點:發哥這下無敵了吧，最大競爭對手被川普關廁所，就問發哥要怎麼輸?--對開放給除了中國以外的國家搶但先加關稅此外台灣關稅還比日韓高所以你要回去縫衣服了嗎?電在哪人在哪?更別提無法取代的一些電子商品，還給中國豁免...所以你要搶什麼?他說台灣在幫中國洗產地，你怎麼看我幫他翻譯一下他說我們對美國的貿易逆差是因為我們幫中國洗產地的關係...XDD不是，你表達出來的意思不是只有我誤會你說我紮稻草人要不要先反省你的表達能力?你不要跟他討論了...沒意義。',\n",
       " '「產能過剩的挑戰」紐時：中國貨湧向歐洲 恐釀經濟災難2025-04-16 02:24 中國新聞組／北京16日電川普政府提高關稅後，歐洲擔憂中國大量出口商品將轉向歐盟市場，衝擊本土產業。',\n",
       " '紐約時報中文網報導，中國生產了大量獲補貼、價格偏低的商品，如電動汽車、電子產品、玩具、鋼材等，多流向美國市場；但川普的高關稅政策讓這些商品面臨壁壘，外界擔心會轉向歐洲，衝擊法國、德國、義大利等國工業。',\n",
       " '先假設川爺的目的真的是這個這得要先計算出有多少是終端市場在美國的三角貿易(應該比2018少一些)把三角貿易的部分扣除後，才是真正中國市場的內需站在美國的立場看，你們只能兩害相權取其輕因為，你們各位全都是出超國，不跟我一起圍堵中國那你就自己去面對中國內捲的過剩產能，跟他一起通縮捲到死誰聽我的話，就給誰多一點肉，台韓重疊的部分如果台灣先納投名狀，韓國扭扭捏捏，那就給台灣10%，韓國20%韓國出口美國的毛利有比台灣多10%嗎? 沒有的話市占就等著被台灣擠掉反過來，如果台灣扭扭捏捏還在幫中國洗產地，偷賣中國先進製程，那就台灣30%韓國10%川爺說了，他是關稅人，關稅是除了上帝之外最美妙的詞彙川爺真心來破壞信用的沒錯，但中國共產黨啥時有信用過了?那個說好的宏都拉斯白蝦呢?假設你一開始的假設正確，川爺不會讓這種國家在美國有太大的市場除非你自己都沒有傳產，不然中國的過剩產能灌進來，你的傳產都要去死你有甚麼中國沒有的東西嗎? 有的話，想賣進來就得跟黨合資把技術跟黨共享，過幾年沒用了再把你踢到一旁這個故事過去三十年上演的還不夠多嗎?這就是川爺打的如意算盤，我先給幾個最早表態的國家最好的deal再放話越晚來的條件越差，你各位就會爭先恐後來找我談了再說一次，這局不是囚徒困境，囚犯們合作不會得到最大利益因為你各位都是出超國，自己吃不下的產能過去都是美國買單沒有美國，你德國製造的豪華車、法國奢侈品跟瑞士名表中國吃得下嗎?韓國的汽車、造船跟消費電子產品，中國跟歐洲吃的下嗎?台積電的先進製程被禁止出口中國了，沒有美國，誰填補GPU的訂單?沒有美國買單，你們滿手都是過剩產能，只能跟中國一起通縮內捲，大家一起失業所以最後，你還是要跟川爺談判，他說晚談不如早談，所以你要不要去談?我不是會衝浪的那種，這四年了不起就定期定額不開槓不借錢，慢慢蹲過去反正2008-2016那種無價也無量的台股也不是沒發生過----你要先扣除在中國設廠來料加工再出口的部分，才是中國內需真正吃下台灣貨品的金額假設川普真的這樣想，那就是我們過去賺取外匯來印新台幣再去炒房炒地的模式要有重大改變了，你要有多一點消費，少一點炒房再怎樣美國都不可能搞到全部自己生產，美國人工太貴沒辦法鎖iphone的螺絲那更慘，把你的製造業都打爛一堆人失業，也不用買中國貨了中國的信用，十年前說你免稅十年後說你逃稅，抓你進黑牢。']"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_same_para(df_query, user_keywords, 'and', k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Step by step demonstration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step1: cut_paragraph() function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>date</th>\n",
       "      <th>category</th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>summary</th>\n",
       "      <th>top_key_freq</th>\n",
       "      <th>tokens</th>\n",
       "      <th>tokens_v2</th>\n",
       "      <th>entities</th>\n",
       "      <th>token_pos</th>\n",
       "      <th>link</th>\n",
       "      <th>photo_link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Stock_04-16_1</td>\n",
       "      <td>2025-04-16</td>\n",
       "      <td>學術股市</td>\n",
       "      <td>[新聞] 日媒：台積電將敲定面板級封裝規格 先從</td>\n",
       "      <td>原文標題：日媒：台積電將敲定面板級封裝規格 先從較小尺寸開始原文連結：發布時間：2025-0...</td>\n",
       "      <td>暫無</td>\n",
       "      <td>暫無</td>\n",
       "      <td>[('台積電', 5), ('原文', 3), ('技術', 3), ('日媒', 2), ...</td>\n",
       "      <td>['原文', '標題', '：', '日媒', '：', '台積電', '將', '敲定',...</td>\n",
       "      <td>['原文', '標題', '日媒', '台積電', '面板級', '規格', '尺寸', '...</td>\n",
       "      <td>[NerToken(word='日媒', ner='NORP', idx=(5, 7)), ...</td>\n",
       "      <td>[('原文', 'Na'), ('標題', 'Na'), ('：', 'COLONCATEG...</td>\n",
       "      <td>https://www.ptt.cc/bbs/Stock/M.1744794518.A.3D...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         item_id        date category                     title  \\\n",
       "0  Stock_04-16_1  2025-04-16     學術股市  [新聞] 日媒：台積電將敲定面板級封裝規格 先從   \n",
       "\n",
       "                                             content sentiment summary  \\\n",
       "0  原文標題：日媒：台積電將敲定面板級封裝規格 先從較小尺寸開始原文連結：發布時間：2025-0...        暫無      暫無   \n",
       "\n",
       "                                        top_key_freq  \\\n",
       "0  [('台積電', 5), ('原文', 3), ('技術', 3), ('日媒', 2), ...   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  ['原文', '標題', '：', '日媒', '：', '台積電', '將', '敲定',...   \n",
       "\n",
       "                                           tokens_v2  \\\n",
       "0  ['原文', '標題', '日媒', '台積電', '面板級', '規格', '尺寸', '...   \n",
       "\n",
       "                                            entities  \\\n",
       "0  [NerToken(word='日媒', ner='NORP', idx=(5, 7)), ...   \n",
       "\n",
       "                                           token_pos  \\\n",
       "0  [('原文', 'Na'), ('標題', 'Na'), ('：', 'COLONCATEG...   \n",
       "\n",
       "                                                link  photo_link  \n",
       "0  https://www.ptt.cc/bbs/Stock/M.1744794518.A.3D...         NaN  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'原文標題：日媒：台積電將敲定面板級封裝規格 先從較小尺寸開始原文連結：發布時間：2025-04-15 14:19記者署名：劉忠勇原文內容：日媒報導，台積電（2330）即將敲定「面板級」先進封裝技術規格，預定最快2027年開始小量試產。據報導，台積電新封裝技術的第一代版本，將採用300x300 mm的方形基板，比先前試做的510×515 mm小得多，但相較於傳統的圓形晶圓可用面積更大。台積電為了嚴格控管品質，決定先採用略小的基板。為加快開發進度，台積電正在桃園興建試產線，目標是在2027年左右開始小量試產。。心得/評論：--南茂哥四年投資友達 資產快腰斬 大獲全勝啦！有夠慘的不少小白推文說很棒喔！真是害死不少人第一 群創沒技術第二 群創股本大 如真貢獻也佔比不到營收5%產能kobe:轉型半導體值得投資'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = df.content[0]\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step1: split paragraphs in text 先將文章切成一個段落一個段落\n",
    "def cut_paragraph(text):\n",
    "    paragraphs = text.split('。')  # 遇到句號就切開\n",
    "    #paragraphs = re.split('。', text) # 遇到句號就切開\n",
    "    #paragraphs = re.split('[。！!？?]', text) # 遇到句號(也納入問號、驚嘆號、分號等)就切開\n",
    "    paragraphs = list(filter(None, paragraphs))\n",
    "    return paragraphs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['原文標題：日媒：台積電將敲定面板級封裝規格 先從較小尺寸開始原文連結：發布時間：2025-04-15 14:19記者署名：劉忠勇原文內容：日媒報導，台積電（2330）即將敲定「面板級」先進封裝技術規格，預定最快2027年開始小量試產',\n",
       " '據報導，台積電新封裝技術的第一代版本，將採用300x300 mm的方形基板，比先前試做的510×515 mm小得多，但相較於傳統的圓形晶圓可用面積更大',\n",
       " '台積電為了嚴格控管品質，決定先採用略小的基板',\n",
       " '為加快開發進度，台積電正在桃園興建試產線，目標是在2027年左右開始小量試產',\n",
       " '心得/評論：--南茂哥四年投資友達 資產快腰斬 大獲全勝啦！有夠慘的不少小白推文說很棒喔！真是害死不少人第一 群創沒技術第二 群創股本大 如真貢獻也佔比不到營收5%產能kobe:轉型半導體值得投資']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paragraphs = cut_paragraph(text)\n",
    "paragraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'民眾捐贈烏克蘭的愛心物資持續湧入外交部，截至今天傍晚累計已收到約4000箱，外交部長吳釗燮中午親自到現場為協助整理物資的志工加油，並對捐贈民眾表達感謝。外交部晚間發布新聞稿指出，外交部從7日開始向民間募集捐贈烏克蘭難民的物資，獲得熱烈響應，親赴外交部捐贈物資的民眾約1730人，加上郵寄包裹，目前約已收到4000箱物資，品項以醫療口罩、毛毯、女性衛生用品、尿片、餅乾等為主，募集活動將持續到18日。外交部表示，為了感謝捐贈民眾，與在現場辛苦分類整理的志工、外交部人員，吳釗燮今天中午特別前往外交部西側門地下停車場視察，吳釗燮與在場的慈濟等民間慈善組織志工，以及其他自發到場幫忙的善心人士親切互動，對於也有烏克蘭旅台人士自願擔任義工在現場協助，吳釗燮特別致意慰問。根據外交部提供的照片，到場幫忙的烏克蘭志工是極為關心家鄉情勢的網紅佳娜。外交部再度提醒有意捐贈物資的民眾，捐贈物品請依照外交部網站所公布的清單為限，切勿捐贈或郵寄二手物品或衣物。送到外交部的捐贈物品務必為全新物品、未拆封包裝、有效期至少6個月以上，以免造成整理及後續轉運捐贈的困擾。募集截止時間是3月18日下午5時以前，民眾可以用面送或郵寄清單所列的20類物品及 14 類藥品至外交部。外交部除感謝熱心民眾踴躍捐贈援助烏克蘭人道物資外，也感謝許多志工義務幫忙、貢獻己力。外交部對各界人士奉獻時間與精神投入國際人道援助，表達最高的敬意。'"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['民眾捐贈烏克蘭的愛心物資持續湧入外交部，截至今天傍晚累計已收到約4000箱，外交部長吳釗燮中午親自到現場為協助整理物資的志工加油，並對捐贈民眾表達感謝',\n",
       " '外交部晚間發布新聞稿指出，外交部從7日開始向民間募集捐贈烏克蘭難民的物資，獲得熱烈響應，親赴外交部捐贈物資的民眾約1730人，加上郵寄包裹，目前約已收到4000箱物資，品項以醫療口罩、毛毯、女性衛生用品、尿片、餅乾等為主，募集活動將持續到18日',\n",
       " '外交部表示，為了感謝捐贈民眾，與在現場辛苦分類整理的志工、外交部人員，吳釗燮今天中午特別前往外交部西側門地下停車場視察，吳釗燮與在場的慈濟等民間慈善組織志工，以及其他自發到場幫忙的善心人士親切互動，對於也有烏克蘭旅台人士自願擔任義工在現場協助，吳釗燮特別致意慰問',\n",
       " '根據外交部提供的照片，到場幫忙的烏克蘭志工是極為關心家鄉情勢的網紅佳娜',\n",
       " '外交部再度提醒有意捐贈物資的民眾，捐贈物品請依照外交部網站所公布的清單為限，切勿捐贈或郵寄二手物品或衣物',\n",
       " '送到外交部的捐贈物品務必為全新物品、未拆封包裝、有效期至少6個月以上，以免造成整理及後續轉運捐贈的困擾',\n",
       " '募集截止時間是3月18日下午5時以前，民眾可以用面送或郵寄清單所列的20類物品及 14 類藥品至外交部',\n",
       " '外交部除感謝熱心民眾踴躍捐贈援助烏克蘭人道物資外，也感謝許多志工義務幫忙、貢獻己力',\n",
       " '外交部對各界人士奉獻時間與精神投入國際人道援助，表達最高的敬意',\n",
       " '']"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.split('。')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['民眾捐贈烏克蘭的愛心物資持續湧入外交部，截至今天傍晚累計已收到約4000箱，外交部長吳釗燮中午親自到現場為協助整理物資的志工加油，並對捐贈民眾表達感謝',\n",
       " '外交部晚間發布新聞稿指出，外交部從7日開始向民間募集捐贈烏克蘭難民的物資，獲得熱烈響應，親赴外交部捐贈物資的民眾約1730人，加上郵寄包裹，目前約已收到4000箱物資，品項以醫療口罩、毛毯、女性衛生用品、尿片、餅乾等為主，募集活動將持續到18日',\n",
       " '外交部表示，為了感謝捐贈民眾，與在現場辛苦分類整理的志工、外交部人員，吳釗燮今天中午特別前往外交部西側門地下停車場視察，吳釗燮與在場的慈濟等民間慈善組織志工，以及其他自發到場幫忙的善心人士親切互動，對於也有烏克蘭旅台人士自願擔任義工在現場協助，吳釗燮特別致意慰問',\n",
       " '根據外交部提供的照片，到場幫忙的烏克蘭志工是極為關心家鄉情勢的網紅佳娜',\n",
       " '外交部再度提醒有意捐贈物資的民眾，捐贈物品請依照外交部網站所公布的清單為限，切勿捐贈或郵寄二手物品或衣物',\n",
       " '送到外交部的捐贈物品務必為全新物品、未拆封包裝、有效期至少6個月以上，以免造成整理及後續轉運捐贈的困擾',\n",
       " '募集截止時間是3月18日下午5時以前，民眾可以用面送或郵寄清單所列的20類物品及 14 類藥品至外交部',\n",
       " '外交部除感謝熱心民眾踴躍捐贈援助烏克蘭人道物資外，也感謝許多志工義務幫忙、貢獻己力',\n",
       " '外交部對各界人士奉獻時間與精神投入國際人道援助，表達最高的敬意']"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paragraphs = text.split('。')\n",
    "list(filter(None, paragraphs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['民眾捐贈烏克蘭的愛心物資持續湧入外交部，截至今天傍晚累計已收到約4000箱，外交部長吳釗燮中午親自到現場為協助整理物資的志工加油，並對捐贈民眾表達感謝',\n",
       " '外交部晚間發布新聞稿指出，外交部從7日開始向民間募集捐贈烏克蘭難民的物資，獲得熱烈響應，親赴外交部捐贈物資的民眾約1730人，加上郵寄包裹，目前約已收到4000箱物資，品項以醫療口罩、毛毯、女性衛生用品、尿片、餅乾等為主，募集活動將持續到18日',\n",
       " '外交部表示，為了感謝捐贈民眾，與在現場辛苦分類整理的志工、外交部人員，吳釗燮今天中午特別前往外交部西側門地下停車場視察，吳釗燮與在場的慈濟等民間慈善組織志工，以及其他自發到場幫忙的善心人士親切互動，對於也有烏克蘭旅台人士自願擔任義工在現場協助，吳釗燮特別致意慰問',\n",
       " '根據外交部提供的照片，到場幫忙的烏克蘭志工是極為關心家鄉情勢的網紅佳娜',\n",
       " '外交部再度提醒有意捐贈物資的民眾，捐贈物品請依照外交部網站所公布的清單為限，切勿捐贈或郵寄二手物品或衣物',\n",
       " '送到外交部的捐贈物品務必為全新物品、未拆封包裝、有效期至少6個月以上，以免造成整理及後續轉運捐贈的困擾',\n",
       " '募集截止時間是3月18日下午5時以前，民眾可以用面送或郵寄清單所列的20類物品及 14 類藥品至外交部',\n",
       " '外交部除感謝熱心民眾踴躍捐贈援助烏克蘭人道物資外，也感謝許多志工義務幫忙、貢獻己力',\n",
       " '外交部對各界人士奉獻時間與精神投入國際人道援助，表達最高的敬意',\n",
       " '']"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.split('[。！!？?]', text) # regular expression 正規式 正則式"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to cut paragraph? \n",
    "\n",
    "    (1) Approach 1:\n",
    "    string.split() (it does not support regex)\n",
    "\n",
    "    (2)Approach 2:\n",
    "    Use regular expression正規式 re.split() \n",
    "    re.split() works fine\n",
    "\n",
    "Simpe example to demonstrate the usage of re.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['這是第1句話', '這是第2句話?這是第3句話', '']"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use string split().  It does not support regex.\n",
    "# Split stentence using delimiter or separator '。'\n",
    "\n",
    "text = '這是第1句話。這是第2句話?這是第3句話。'\n",
    "text.split('。')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['這是第1句話。這是第2句話?這是第3句話。']"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# It doesn't work. string split() method does not support regex\n",
    "text.split('[。?]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['這是第1句話', '這是，第2句話?這是--第3句話', '']"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.split('。', \"這是第1句話。這是，第2句話?這是--第3句話。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 如果納入多個符號去切割，必須用regular expression\n",
    "# Here, [abc] will match if the string you are trying to match contains any of the a, b or c . \n",
    "# You can also specify a range of characters using - inside square brackets. [a-e] is the same as [abcde] . [1-4] is the same as [1234] .\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['這是第1句話', '這是，第2句話', '這是--第3句話', '']"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# separator:。 ?\n",
    "re.split('[。?]', \"這是第1句話。這是，第2句話?這是--第3句話。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['這是第1句話', '這是，第2句話', '這是--第3句話', '']"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \"|\" means or 可以加上｜去分隔開來，特別適用於當切割符號是由多個字組成時。\n",
    "# separator:。 ?\n",
    "re.split(r'[。|?]', \"這是第1句話。這是，第2句話?這是--第3句話。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['這', '第1', '', '。這', '，第2', '', '?這', '--第3', '', '。']"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \"|\" means or\n",
    "# separator:。 ?\n",
    "re.split('[句話|是]', \"這是第1句話。這是，第2句話?這是--第3句話。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['這', '第1', '', '。這', '，第2', '', '?這', '--第3', '', '。']"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \"|\" means or\n",
    "# separator:。 ?\n",
    "re.split('[句話 是]', \"這是第1句話。這是，第2句話?這是--第3句話。\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How to remove the empty elements?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do you notice the last element is an empty string?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = re.split(r'[。?]', \"這是第1句話。這是，第2句話?這是--第3句話。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<filter at 0x2df45b5dd80>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using Python filter function\n",
    "filter(None, result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['這是第1句話', '這是，第2句話', '這是--第3句話']"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(filter(None, result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['這是第1句話', '這是，第2句話', '這是--第3句話']"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# An alternative way\n",
    "[item for item in result if item]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Find paragraphs containing keywords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All-in-one function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "# Find out all paragraphs where multiple keywords occur.\n",
    "def get_same_para(df_query, user_keywords, cond, k=30):\n",
    "    same_para=[]\n",
    "    for text in df_query.content:\n",
    "        #print(text)\n",
    "        paragraphs = cut_paragraph(text)\n",
    "        for para in paragraphs:\n",
    "            para += \"。\"  # 在每段落文字後面加一個句號。\n",
    "            # 判斷每個段落文字是否包含該關鍵字，and or分開判斷\n",
    "            if cond == 'and':\n",
    "                if all([kw in para for kw in user_keywords]):\n",
    "                    same_para.append(para)  # 符合條件的段落para保存起來\n",
    "            elif cond == 'or':\n",
    "                if any([kw in para for kw in user_keywords]):\n",
    "                    same_para.append(para)  # 符合條件的段落para保存起來\n",
    "    return same_para[0:k]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_keywords = ['川普','關稅']\n",
    "cond='and'\n",
    "cate='全部'\n",
    "weeks=2\n",
    "df_query = filter_dataFrame_fullText(user_keywords, cond, cate, weeks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['最後，回到我是投資人的位置，關注所有後續經證實的可能影響經濟格局變化的政策，是極需要的；例如前幾天美國海關CBP宣布部份產品及部份高科技產品豁免清單，但仍有變數（半導體關稅、芬太尼關稅）如果以台灣及其它國家來看，最大受益者目前是台灣（在豁免比例與產品範圍-高於其他國家，更在高附加價值的半導體與科技零組件領域，占據少數真正受惠的核心位置）因此關注後續1. 90天後（至7月9號）台灣的談判結果，2. 還有7/9後各國實際公佈談判條件，（跟其他國家影響比較，希望台灣不要比他國差或差太多）3 韓國不久前宣布200億鎂以上的晶片產業扶持計畫，（關注未來程度是否可能會影響台灣未來利益；4. 半導體關稅、芬太尼關稅後續5. 礦產關稅後續 會再如何影響國際局勢（川普已簽署一項命令，指示商務部調查所有「關鍵礦產」的進口情況，確認徵收關稅的可能性）。',\n",
       " '川普大讚「關稅政策」有效！\\u3000發文激讚：美國通膨下降了ETTODAY2025年04月16日 15:55記者吳美依／綜合報導美國總統川普發文表示，美國的通貨膨脹已經下降了，這一切都要歸功於關稅政策，儘管最近的全球市場動盪，正是他頒布的「對等關稅」所引起。',\n",
       " '剛剛在自家社群媒體Truth Social發文表示，川普14日在白宮會見薩爾瓦多總統布格磊（Nayib Bukele）表示，根據最新消費者物價報告，，川普宣布鬆綁一些關稅措施之後，全球股市於14日回彈。',\n",
       " '」此外，輝達（Nvidia）宣布將首度在美國生產AI超級電腦，而川普也將這件事，視為關稅政策取得成功的證據，「這是你所聽過最重大的公告之一，因為正如你們知道的，輝達幾乎控制著整個產業，這是世上最重要的產業之一。',\n",
       " '」認為，輝達之所以這麼做，是因為他在去年11月5日當選，並且實施了關稅，心得評論：對等關稅4月才實施（除中國加徵至145-245%，其他經濟體暫緩90天剩10%），墨加關稅4月2號才正式實施，三月有的關稅大概就鋼鋁關稅25%，現在就出來吹了，恐怕要看到真實影響數據還要再幾個月吧？--油價是OPEC+的關係吧（？）鮑爾就要軟著陸成功 半途殺出川普搞砸一切，要是川普不這樣搞，可能真的可以軟著陸。',\n",
       " '感覺上你在反串不過中國的確在擺爛，而且早在川普發動關稅戰前就在擺爛中國要經濟轉型、要促進內需這套說法從胡錦濤時代就一直講了講到現在中國的內需還是過低中國加入WTO快25年，幾乎把世界市場吃了一大半結果不僅沒有辦法培養出相應的內需市場反而養出了一個頭重腳輕的怪胎就算今天不是川普發難，遲早也會有其他的美國總統或歐盟政治領袖採取動作川普被人抨擊的並不是針對中國這點，而是手段粗暴欠缺考量，地圖砲朝盟友開習近平的確是在擺爛，比較跟中國差不多人均GDP的國家中國的社會保障、社會安全這塊也是倒數的那就演變成國富民窮的情況民間超額儲蓄 > 儲蓄投入房地產 > 房地產泡沫，資產損失 > 消費更加緊縮中國政府這個時候不僅沒有想辦法去降低人民負擔反而還要加緊集中權力、收攏資源備戰也就是習近平認為現在是東昇西降，是百年難得一遇的戰略機遇他要強化集權、重新集中資源去打一場自認的\"國運之戰\"美國無謀引戰在先，但影響更大的，恐怕會是上述中國的誤判如果關稅戰爛尾還好，經濟就動盪個小半年就是川普個人政治生涯終結，大家事後慢慢修補他造成的破壞如果關稅戰無意觸發了中美之間全面性的對抗，經濟世界大戰後果不堪設想所謂 \"結束所有戰爭的戰爭\" 或 \"一戰定乾坤\" 從來都是妄想這點不管是熱戰、冷戰、經濟戰、科技戰都一樣--。',\n",
       " '原文標題：「中國扛不住245％關稅」大量工廠放長假了！2000萬人慘失業原文連結：發布時間：2025-04-16記者署名：林瑩真原文內容：隨著美國總統川普再度祭出對中高額關稅，中國經濟面臨新一波衝擊。',\n",
       " '川普關稅重擊中國出口，中國企業停產裁員潮蔓延自美方啟動貿易戰以來，中國多數出口導向企業生產計畫紛紛停擺，許多工廠選擇提前放長假，長江三角洲與珠江三角洲地區更出現大規模裁員潮，失業農民工紛紛返鄉，被迫「提前過年」。',\n",
       " '美國總統川普本月9日授權對多國祭出的對等關稅措施暫停實施90天，在這段期間僅課徵10%的關稅，立即生效，但對中國進口商品課徵關稅總稅率提高至145%。',\n",
       " '同樣，在貿易戰中，川普通過對中國加徵關稅，施加壓力，這讓許多美國企業和消費者感受到了一定的短期經濟損失。']"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_same_para(df_query, user_keywords, 'and', k=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step by step demonstration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>date</th>\n",
       "      <th>category</th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>summary</th>\n",
       "      <th>top_key_freq</th>\n",
       "      <th>tokens</th>\n",
       "      <th>tokens_v2</th>\n",
       "      <th>entities</th>\n",
       "      <th>token_pos</th>\n",
       "      <th>link</th>\n",
       "      <th>photo_link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stock_04-16_2</td>\n",
       "      <td>2025-04-16</td>\n",
       "      <td>學術股市</td>\n",
       "      <td>Re: [新聞] 川普傳打算以關稅談判孤立中國 可能要各</td>\n",
       "      <td>從廣場協議看2018美中貿易戰 的升級版，及這次的關稅事件，廣場協議的主因也是貿易逆差跟美元...</td>\n",
       "      <td>暫無</td>\n",
       "      <td>暫無</td>\n",
       "      <td>[('中國', 36), ('美國', 30), ('國家', 21), ('技術', 13...</td>\n",
       "      <td>['從', '廣場', '協議', '看', '2018', '美中', '貿易戰 ', '...</td>\n",
       "      <td>['廣場', '協議', '美中', '貿易戰 ', '升級版', '關稅', '事件', ...</td>\n",
       "      <td>[NerToken(word='美國鋼鐵', ner='ORG', idx=(57, 61)...</td>\n",
       "      <td>[('從', 'P'), ('廣場', 'Nc'), ('協議', 'Na'), ('看',...</td>\n",
       "      <td>https://www.ptt.cc/bbs/Stock/M.1744794681.A.85...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         item_id        date category                         title  \\\n",
       "1  Stock_04-16_2  2025-04-16     學術股市  Re: [新聞] 川普傳打算以關稅談判孤立中國 可能要各   \n",
       "\n",
       "                                             content sentiment summary  \\\n",
       "1  從廣場協議看2018美中貿易戰 的升級版，及這次的關稅事件，廣場協議的主因也是貿易逆差跟美元...        暫無      暫無   \n",
       "\n",
       "                                        top_key_freq  \\\n",
       "1  [('中國', 36), ('美國', 30), ('國家', 21), ('技術', 13...   \n",
       "\n",
       "                                              tokens  \\\n",
       "1  ['從', '廣場', '協議', '看', '2018', '美中', '貿易戰 ', '...   \n",
       "\n",
       "                                           tokens_v2  \\\n",
       "1  ['廣場', '協議', '美中', '貿易戰 ', '升級版', '關稅', '事件', ...   \n",
       "\n",
       "                                            entities  \\\n",
       "1  [NerToken(word='美國鋼鐵', ner='ORG', idx=(57, 61)...   \n",
       "\n",
       "                                           token_pos  \\\n",
       "1  [('從', 'P'), ('廣場', 'Nc'), ('協議', 'Na'), ('看',...   \n",
       "\n",
       "                                                link  photo_link  \n",
       "1  https://www.ptt.cc/bbs/Stock/M.1744794681.A.85...         NaN  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_query.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'從廣場協議看2018美中貿易戰 的升級版，及這次的關稅事件，廣場協議的主因也是貿易逆差跟美元過強，當時的時代背景-美國鋼鐵重鎮跟底特律汽車王國-從曾經是世界第一的位置 被日本超越，美國大量進口日本鋼鐵及汽車，導致本土產業利潤被壓縮，造成大規模就業流失，美國主要針對貿易逆差最大的對象-日本，跟多國簽廣場協議，對日本的主要影響-日幣升值，影響對美國出口商品利潤下降，2018則是中國崛起，但是威脅到美國，中國不是合作者的態度跟做事方法，而是例如強迫去到中國投資的外國企業-技術轉移，或是偷取技術或資料，轉移或偷取後，過幾年就開設同類型的公司競爭，然後政府補貼，取得市佔後賣到包含轉移或偷取技術的國家及其它國家，-傾銷。中國以補貼再傾銷到其他國家的產業已不在少數，面板，太陽能，手機，電動車，化妝品，甚至成熟製程晶片，及其它產業，現在中國成熟製程晶片也已經快到可以傾銷的地步，所以之前聯電股價受影響吧我想，如果拋開政黨意識或人物爭議，假設當年李登輝總統沒有立下政策限制-台積電技術在外國設廠，必須保持落後台灣技術一代，以中國政府補貼產業的態度，現在的台積電會是什麼模樣？如果讓中國也掌握先進製程晶片技術，也政府補貼及大量製造，然後傾銷各國，台積電怎麼辦？現在還會是領先全球的技術位置嗎？然後中國現在即使在美國限制先進晶片製程及設備的情況下，照樣能透過新加坡走私AI晶片，到了新加坡成為走私最大國之一的程度，也能利用白手套公司，騙取讓台積電幫忙代工，因為維持現狀的話，中國離掌握最先進科技的進度越來越近；如果等到中國真的做到掌握先進製程晶片技術，當全世界所有最賺錢 最科技先進的產業在中國手中，從手機，電動車到電腦到先進製程的AI晶片然後到軍火，進而成為世界霸主，中國會怎麼做？會怎麼對待其它國家？所有其它國家裡面，尤其以我們台灣而言，是好還是不好？中國成為世界霸主，跟美國是世界霸主的差別是什麼？見微知著，看中國現在整體經濟跟人民幸福度，還有所有跟中國合作的國家例如一帶一路，經濟情況都沒有更好，所以如果中國在取得世界霸主地位之後，即使是站它隊的，我覺得頂多也只有少數人享有好處。而如果把美國跟中國擬人化，看它們的“人品”（我們如果不看誰比較好，只看誰比較不好）美國根據已知歷史，幫助過日韓還有中國及其它國家的經濟或教育或醫療，整體結果大都為正面效果，而中國的幫助，通常是幫到他國的基礎建設可以被中國租用百年左右，還欠中國一屁股債或經濟倒退，例如斯里蘭卡的漢班托塔港，都是負面效果。而美國在廣場協議也只是讓日幣升值，人品比較起來，稍微比較好一點。所以如果我是其它國家的“領導人”這個位置，先不代入什麼國家跟人，盡可能選擇利益最佳化或盡量減輕降低傷害程度，我的選擇只有兩條路，站中國的，或站美國的隊；那麼我不會考慮站中國的隊。那如果想推測之後局勢發展，“我會先想像自己是中國領導人”一樣先不代入什麼人，盡可能只是客觀想像“中國領導人”這個位置的利益最佳化，那麼我會採取手段各種利誘威脅，分化各國，然後我會繼續追趕最先進科技的程度，以達到掌握最先進科技，掌握各種最重要有形無形資源，掌握最賺錢產業及技術，各種入股併購，盡可能賺其它國家的錢，越多越好，然後我會透過經濟力量-更改規則甚至創造規則，其它國家的利潤資源都會越來越被壓縮，形成惡性循環，他們的政商會更勾結，那麼全世界包含中國的一般中低階層百姓都會更辛苦；再想像如果我是美國總統的位置，一樣先不代入人，盡可能只是客觀想像這個位置的利益最佳化或最降低風險或傷害程度；“如果我是美國總統”我會盡力與其它國家合作，如果不能中斷中國的野心做法，也盡可能去延緩，當初廣場協議後，不過幾年 互聯網時代崛起，（我自己猜測，這可能也是美國鋼鐵跟汽車工業沒有恢復昔日榮景-美國政府沒有去解決根本問題，而是把重心放在互聯網科技）所以延緩中國取得先進科技進度，也許美國可以再取得類似互聯網這樣下一個大跨越程度的科技創新，雖然要再度防範中國偷取技術，但就是保持領先。所以在美國總統的位置，讓台積電過去，是那個位置的必然選擇。想像中國跟美國兩個大方向後，代入如果我是台灣總統的位置，慶幸目前大方向看起來一致，不是站中國的隊，“如果我是台灣總統的位置”一樣先不代入人，不代入政黨，盡可能客觀找出利益最佳化或盡量降低傷害程度的選擇，我會配合過去美國設廠，只要是美國希望的；但談判交涉過程我希望盡可能爭取利益最佳化或盡量減輕降低傷害的程度，不過目前談判資訊都是未透明的，我本來最關心台積電如果過去設廠，能不能保持李登輝總統政策，技術落後台灣一代，但。總之已決定或已進行中的，我想像也於事無補，因此想像到這邊就好；然後關於其它國家-與美國中國合作的利弊分析，我相信其它國家評估更多，只是可能礙於政治而選擇放出什麼訊息，所以關於其它國家之間，未實際宣布合作項目或政策，都可以更加保持媒體消息識別判讀。上面對不同角色的想像都盡量先不代入人，盡可能客觀想像符合位置的最佳利益或減輕降低風險傷害的大方向，代入人後，才依其言行、方式跟手段評估風險。所以在這樣的局勢環境，選擇投資或避開投資什麼產業，我個人會寧願避開主要戰場，（在代入什麼人後的評估風險考量），那麼，美國總統現在要達成要維護的，通通都是他的痛點：減低美債壓力（要求各國投資、買美債、捐款）縮短貿易逆差（關稅、匯率-希望各國貨幣升值）製造業回流（AI晶片 資料中心 通訊設備 汽車）農產品跟鋼鐵（內需-選舉票倉）都也可能會成為中國或跟中國合作的國家的報復戰場，或是美國為了限制或延緩中國，即使會有犧牲但仍必要的政策，（進而影響投資人/機構心理因素，影響投資價格變動較大）。最後，回到我是投資人的位置，關注所有後續經證實的可能影響經濟格局變化的政策，是極需要的；例如前幾天美國海關CBP宣布部份產品及部份高科技產品豁免清單，但仍有變數（半導體關稅、芬太尼關稅）如果以台灣及其它國家來看，最大受益者目前是台灣（在豁免比例與產品範圍-高於其他國家，更在高附加價值的半導體與科技零組件領域，占據少數真正受惠的核心位置）因此關注後續1. 90天後（至7月9號）台灣的談判結果，2. 還有7/9後各國實際公佈談判條件，（跟其他國家影響比較，希望台灣不要比他國差或差太多）3 韓國不久前宣布200億鎂以上的晶片產業扶持計畫，（關注未來程度是否可能會影響台灣未來利益；4. 半導體關稅、芬太尼關稅後續5. 礦產關稅後續 會再如何影響國際局勢（川普已簽署一項命令，指示商務部調查所有「關鍵礦產」的進口情況，確認徵收關稅的可能性）。6. 這兩天新聞-美國政府要求輝達H20和AMD-MI308晶片需申請許可才能出口至中國等地，這表示美國高科技企業產品都隨時可能受美國政府政策出口管制而影響獲利成長速度，（也關注未來其它美國產品受政策出口管制）7. 關注中國取得最先進科技技術進度，8. 技術不容易被偷取的台股，9. 美國希望過去美國設廠的重要科技供應鏈的，例如輝達宣布與緯創鴻海等合作，10. 生產重心不是在中國的，11. 或有移轉產能在其它國家的，（看懂局勢看得遠或足夠風險意識或能力足夠的台商，在幾年前應該就要能推測未來經濟格局變化，早早轉移產能）凡是現在生產重心，還主要在中國，而沒有在其它國家已設廠或進行中的，（個人覺得都可以不用考慮投資，因為以它們看局勢或風險意識或其它能力，說能賺很多錢-創造營收並穩定成長，個人覺得機率極低。）--'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = df_query.content.iloc[0]\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['從廣場協議看2018美中貿易戰 的升級版，及這次的關稅事件，廣場協議的主因也是貿易逆差跟美元過強，當時的時代背景-美國鋼鐵重鎮跟底特律汽車王國-從曾經是世界第一的位置 被日本超越，美國大量進口日本鋼鐵及汽車，導致本土產業利潤被壓縮，造成大規模就業流失，美國主要針對貿易逆差最大的對象-日本，跟多國簽廣場協議，對日本的主要影響-日幣升值，影響對美國出口商品利潤下降，2018則是中國崛起，但是威脅到美國，中國不是合作者的態度跟做事方法，而是例如強迫去到中國投資的外國企業-技術轉移，或是偷取技術或資料，轉移或偷取後，過幾年就開設同類型的公司競爭，然後政府補貼，取得市佔後賣到包含轉移或偷取技術的國家及其它國家，-傾銷',\n",
       " '中國以補貼再傾銷到其他國家的產業已不在少數，面板，太陽能，手機，電動車，化妝品，甚至成熟製程晶片，及其它產業，現在中國成熟製程晶片也已經快到可以傾銷的地步，所以之前聯電股價受影響吧我想，如果拋開政黨意識或人物爭議，假設當年李登輝總統沒有立下政策限制-台積電技術在外國設廠，必須保持落後台灣技術一代，以中國政府補貼產業的態度，現在的台積電會是什麼模樣？如果讓中國也掌握先進製程晶片技術，也政府補貼及大量製造，然後傾銷各國，台積電怎麼辦？現在還會是領先全球的技術位置嗎？然後中國現在即使在美國限制先進晶片製程及設備的情況下，照樣能透過新加坡走私AI晶片，到了新加坡成為走私最大國之一的程度，也能利用白手套公司，騙取讓台積電幫忙代工，因為維持現狀的話，中國離掌握最先進科技的進度越來越近；如果等到中國真的做到掌握先進製程晶片技術，當全世界所有最賺錢 最科技先進的產業在中國手中，從手機，電動車到電腦到先進製程的AI晶片然後到軍火，進而成為世界霸主，中國會怎麼做？會怎麼對待其它國家？所有其它國家裡面，尤其以我們台灣而言，是好還是不好？中國成為世界霸主，跟美國是世界霸主的差別是什麼？見微知著，看中國現在整體經濟跟人民幸福度，還有所有跟中國合作的國家例如一帶一路，經濟情況都沒有更好，所以如果中國在取得世界霸主地位之後，即使是站它隊的，我覺得頂多也只有少數人享有好處',\n",
       " '而如果把美國跟中國擬人化，看它們的“人品”（我們如果不看誰比較好，只看誰比較不好）美國根據已知歷史，幫助過日韓還有中國及其它國家的經濟或教育或醫療，整體結果大都為正面效果，而中國的幫助，通常是幫到他國的基礎建設可以被中國租用百年左右，還欠中國一屁股債或經濟倒退，例如斯里蘭卡的漢班托塔港，都是負面效果',\n",
       " '而美國在廣場協議也只是讓日幣升值，人品比較起來，稍微比較好一點',\n",
       " '所以如果我是其它國家的“領導人”這個位置，先不代入什麼國家跟人，盡可能選擇利益最佳化或盡量減輕降低傷害程度，我的選擇只有兩條路，站中國的，或站美國的隊；那麼我不會考慮站中國的隊',\n",
       " '那如果想推測之後局勢發展，“我會先想像自己是中國領導人”一樣先不代入什麼人，盡可能只是客觀想像“中國領導人”這個位置的利益最佳化，那麼我會採取手段各種利誘威脅，分化各國，然後我會繼續追趕最先進科技的程度，以達到掌握最先進科技，掌握各種最重要有形無形資源，掌握最賺錢產業及技術，各種入股併購，盡可能賺其它國家的錢，越多越好，然後我會透過經濟力量-更改規則甚至創造規則，其它國家的利潤資源都會越來越被壓縮，形成惡性循環，他們的政商會更勾結，那麼全世界包含中國的一般中低階層百姓都會更辛苦；再想像如果我是美國總統的位置，一樣先不代入人，盡可能只是客觀想像這個位置的利益最佳化或最降低風險或傷害程度；“如果我是美國總統”我會盡力與其它國家合作，如果不能中斷中國的野心做法，也盡可能去延緩，當初廣場協議後，不過幾年 互聯網時代崛起，（我自己猜測，這可能也是美國鋼鐵跟汽車工業沒有恢復昔日榮景-美國政府沒有去解決根本問題，而是把重心放在互聯網科技）所以延緩中國取得先進科技進度，也許美國可以再取得類似互聯網這樣下一個大跨越程度的科技創新，雖然要再度防範中國偷取技術，但就是保持領先',\n",
       " '所以在美國總統的位置，讓台積電過去，是那個位置的必然選擇',\n",
       " '想像中國跟美國兩個大方向後，代入如果我是台灣總統的位置，慶幸目前大方向看起來一致，不是站中國的隊，“如果我是台灣總統的位置”一樣先不代入人，不代入政黨，盡可能客觀找出利益最佳化或盡量降低傷害程度的選擇，我會配合過去美國設廠，只要是美國希望的；但談判交涉過程我希望盡可能爭取利益最佳化或盡量減輕降低傷害的程度，不過目前談判資訊都是未透明的，我本來最關心台積電如果過去設廠，能不能保持李登輝總統政策，技術落後台灣一代，但',\n",
       " '總之已決定或已進行中的，我想像也於事無補，因此想像到這邊就好；然後關於其它國家-與美國中國合作的利弊分析，我相信其它國家評估更多，只是可能礙於政治而選擇放出什麼訊息，所以關於其它國家之間，未實際宣布合作項目或政策，都可以更加保持媒體消息識別判讀',\n",
       " '上面對不同角色的想像都盡量先不代入人，盡可能客觀想像符合位置的最佳利益或減輕降低風險傷害的大方向，代入人後，才依其言行、方式跟手段評估風險',\n",
       " '所以在這樣的局勢環境，選擇投資或避開投資什麼產業，我個人會寧願避開主要戰場，（在代入什麼人後的評估風險考量），那麼，美國總統現在要達成要維護的，通通都是他的痛點：減低美債壓力（要求各國投資、買美債、捐款）縮短貿易逆差（關稅、匯率-希望各國貨幣升值）製造業回流（AI晶片 資料中心 通訊設備 汽車）農產品跟鋼鐵（內需-選舉票倉）都也可能會成為中國或跟中國合作的國家的報復戰場，或是美國為了限制或延緩中國，即使會有犧牲但仍必要的政策，（進而影響投資人/機構心理因素，影響投資價格變動較大）',\n",
       " '最後，回到我是投資人的位置，關注所有後續經證實的可能影響經濟格局變化的政策，是極需要的；例如前幾天美國海關CBP宣布部份產品及部份高科技產品豁免清單，但仍有變數（半導體關稅、芬太尼關稅）如果以台灣及其它國家來看，最大受益者目前是台灣（在豁免比例與產品範圍-高於其他國家，更在高附加價值的半導體與科技零組件領域，占據少數真正受惠的核心位置）因此關注後續1. 90天後（至7月9號）台灣的談判結果，2. 還有7/9後各國實際公佈談判條件，（跟其他國家影響比較，希望台灣不要比他國差或差太多）3 韓國不久前宣布200億鎂以上的晶片產業扶持計畫，（關注未來程度是否可能會影響台灣未來利益；4. 半導體關稅、芬太尼關稅後續5. 礦產關稅後續 會再如何影響國際局勢（川普已簽署一項命令，指示商務部調查所有「關鍵礦產」的進口情況，確認徵收關稅的可能性）',\n",
       " '6. 這兩天新聞-美國政府要求輝達H20和AMD-MI308晶片需申請許可才能出口至中國等地，這表示美國高科技企業產品都隨時可能受美國政府政策出口管制而影響獲利成長速度，（也關注未來其它美國產品受政策出口管制）7. 關注中國取得最先進科技技術進度，8. 技術不容易被偷取的台股，9. 美國希望過去美國設廠的重要科技供應鏈的，例如輝達宣布與緯創鴻海等合作，10. 生產重心不是在中國的，11. 或有移轉產能在其它國家的，（看懂局勢看得遠或足夠風險意識或能力足夠的台商，在幾年前應該就要能推測未來經濟格局變化，早早轉移產能）凡是現在生產重心，還主要在中國，而沒有在其它國家已設廠或進行中的，（個人覺得都可以不用考慮投資，因為以它們看局勢或風險意識或其它能力，說能賺很多錢-創造營收並穩定成長，個人覺得機率極低',\n",
       " '）--']"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paragraphs = cut_paragraph(text)\n",
    "paragraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['最後，回到我是投資人的位置，關注所有後續經證實的可能影響經濟格局變化的政策，是極需要的；例如前幾天美國海關CBP宣布部份產品及部份高科技產品豁免清單，但仍有變數（半導體關稅、芬太尼關稅）如果以台灣及其它國家來看，最大受益者目前是台灣（在豁免比例與產品範圍-高於其他國家，更在高附加價值的半導體與科技零組件領域，占據少數真正受惠的核心位置）因此關注後續1. 90天後（至7月9號）台灣的談判結果，2. 還有7/9後各國實際公佈談判條件，（跟其他國家影響比較，希望台灣不要比他國差或差太多）3 韓國不久前宣布200億鎂以上的晶片產業扶持計畫，（關注未來程度是否可能會影響台灣未來利益；4. 半導體關稅、芬太尼關稅後續5. 礦產關稅後續 會再如何影響國際局勢（川普已簽署一項命令，指示商務部調查所有「關鍵礦產」的進口情況，確認徵收關稅的可能性）。']"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find out all paragraphs where multiple keywords occur.\n",
    "user_keywords = ['川普','關稅']\n",
    "cond='and'\n",
    "same_para=[] # 存放含有關鍵字的段落\n",
    "for para in paragraphs:\n",
    "    para += \"。\" # 在每段落文字後面加一個句號。\n",
    "    # 判斷每個段落文字是否包含該關鍵字，and or分開判斷\n",
    "    if cond=='and': \n",
    "        if all([kw in para for kw in user_keywords]):\n",
    "            same_para.append(para) # 符合條件的段落para保存起來\n",
    "    elif cond=='or':\n",
    "        if any([kw in para for kw in user_keywords]):\n",
    "            same_para.append(para)  # 符合條件的段落para保存起來\n",
    "same_para\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### multiple words in text (easier way)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "para = '民進黨重用派系、酬庸人事的部分，他不再贅述；不過，他也批評國民黨，前總統馬英九的「交通幫」，沒有解決桃園機場跑道和漏水的問題，馬政府有許多人害怕跟宋楚瑜多接觸，擔心因此被老闆換掉，同樣是小氣、沒有肚量。'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_keywords = ['馬英九','宋楚瑜']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "any([kw in para for kw in user_keywords])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all([kw in para for kw in user_keywords])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_keywords = ['馬英九','蔡英文']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "any([kw in para for kw in user_keywords])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all([kw in para for kw in user_keywords])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### re.search(): An alternative way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['最後，回到我是投資人的位置，關注所有後續經證實的可能影響經濟格局變化的政策，是極需要的；例如前幾天美國海關CBP宣布部份產品及部份高科技產品豁免清單，但仍有變數（半導體關稅、芬太尼關稅）如果以台灣及其它國家來看，最大受益者目前是台灣（在豁免比例與產品範圍-高於其他國家，更在高附加價值的半導體與科技零組件領域，占據少數真正受惠的核心位置）因此關注後續1. 90天後（至7月9號）台灣的談判結果，2. 還有7/9後各國實際公佈談判條件，（跟其他國家影響比較，希望台灣不要比他國差或差太多）3 韓國不久前宣布200億鎂以上的晶片產業扶持計畫，（關注未來程度是否可能會影響台灣未來利益；4. 半導體關稅、芬太尼關稅後續5. 礦產關稅後續 會再如何影響國際局勢（川普已簽署一項命令，指示商務部調查所有「關鍵礦產」的進口情況，確認徵收關稅的可能性）。']"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# An alternative way for advanced users: using re.seach()\n",
    "# Alternative approach using re.search() for reference\n",
    "user_keywords = ['川普','關稅']\n",
    "cond='and'\n",
    "same_para=[] # 存放含有關鍵字的段落\n",
    "for para in paragraphs:\n",
    "    para += \"。\"\n",
    "    if cond=='and':\n",
    "        if all([re.search(kw, para) for kw in user_keywords]):\n",
    "            same_para.append(para)\n",
    "    elif cond=='or':\n",
    "        if any([re.search(kw, para) for kw in user_keywords]):\n",
    "            same_para.append(para)\n",
    "same_para\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '民進黨重用派系、酬庸人事的部分，他不再贅述；不過，他也批評國民黨，前總統馬英九的「交通幫」，沒有解決桃園機場跑道和漏水的問題，馬政府有許多人害怕跟宋楚瑜多接觸，擔心因此被老闆換掉，同樣是小氣、沒有肚量。'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = ['馬英九','蔡英文']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "any([re.search(kw, text) for kw in user_keywords])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all([re.search(kw, text) for kw in user_keywords])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# views.py in Django website"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To save memory, we just import df from the other app as follows.\n",
    "from app_user_keyword.views import df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'app_user_keyword'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[102], line 28\u001b[0m\n\u001b[0;32m     21\u001b[0m     df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mapp_user_keyword/dataset/cna_news_preprocessed.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, sep\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m|\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# (3) df can be import from app_user_keyword 隔壁app的變數\u001b[39;00m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# To save memory, we just import df from the other app as follows.\u001b[39;00m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# from app_user_keyword.views import df\u001b[39;00m\n\u001b[0;32m     26\u001b[0m \n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# (4) df can be import from app_user_keyword  隔壁app的變數\u001b[39;00m\n\u001b[1;32m---> 28\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mapp_user_keyword\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mviews\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01muserkeyword_views\u001b[39;00m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_df_data\u001b[39m():\n\u001b[0;32m     30\u001b[0m     \u001b[38;5;66;03m# import and use df from app_user_keyword \u001b[39;00m\n\u001b[0;32m     31\u001b[0m     \u001b[38;5;28;01mglobal\u001b[39;00m df \u001b[38;5;66;03m# global variable\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'app_user_keyword'"
     ]
    }
   ],
   "source": [
    "from django.shortcuts import render\n",
    "from django.views.decorators.csrf import csrf_exempt\n",
    "from django.http import JsonResponse\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "import pandas as pd\n",
    "import math\n",
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "# (1) we can load data using read_csv() 自己app的csv檔案\n",
    "# global variable\n",
    "# df = pd.read_csv('dataset/cna_news_200_preprocessed.csv', sep='|')\n",
    "\n",
    "\n",
    "# (2) we can load data using reload_df_data() function 隔壁app的csv檔案\n",
    "# global variable\n",
    "def load_df_data_v1():\n",
    "    # global variable\n",
    "    global  df\n",
    "    df = pd.read_csv('app_user_keyword/dataset/cna_news_200_preprocessed.csv', sep='|')\n",
    "\n",
    "# (3) df can be import from app_user_keyword 隔壁app的變數\n",
    "# To save memory, we just import df from the other app as follows.\n",
    "# from app_user_keyword.views import df\n",
    "\n",
    "# (4) df can be import from app_user_keyword  隔壁app的變數\n",
    "import app_user_keyword.views as userkeyword_views\n",
    "def load_df_data():\n",
    "    # import and use df from app_user_keyword \n",
    "    global df # global variable\n",
    "    df = userkeyword_views.df\n",
    "\n",
    "load_df_data()\n",
    "\n",
    "\n",
    "# For the key association analysis\n",
    "def home(request):\n",
    "    return render(request, 'app_user_keyword_association/home.html')\n",
    "\n",
    "# df_query should be global\n",
    "@csrf_exempt\n",
    "def api_get_userkey_associate(request):\n",
    "    userkey = request.POST.get('userkey')\n",
    "    cate = request.POST['cate'] # This is an alternative way to get POST data.\n",
    "    cond = request.POST.get('cond')\n",
    "    weeks = int(request.POST.get('weeks'))\n",
    "    key = userkey.split()\n",
    "\n",
    "    #global  df_query # global variable It's not necessary.\n",
    "\n",
    "    df_query = filter_dataFrame_fullText(key, cond, cate,weeks)\n",
    "\n",
    "    # if df_query is empty, return an error message\n",
    "    if len(df_query) == 0:\n",
    "        return JsonResponse({'error': 'No results found for the given keywords.'})\n",
    "    \n",
    "    newslinks = get_title_link_topk(df_query, k=15)\n",
    "    related_words, clouddata = get_related_word_clouddata(df_query)\n",
    "    same_paragraph = get_same_para(df_query, key, cond, k=10) # multiple keywords\n",
    "\n",
    "\n",
    "    response = {\n",
    "        'newslinks': newslinks,\n",
    "        'related_words': related_words,\n",
    "        'same_paragraph': same_paragraph,\n",
    "        'clouddata':clouddata,\n",
    "        'num_articles': len(df_query),\n",
    "    }\n",
    "    return JsonResponse(response)\n",
    "\n",
    "# Searching keywords from \"content\" column\n",
    "# Here this function uses df.content column, while filter_dataFrame() uses df.tokens_v2\n",
    "def filter_dataFrame_fullText(user_keywords, cond, cate, weeks):\n",
    "\n",
    "    # end date: the date of the latest record of news\n",
    "    end_date = df.date.max()\n",
    "\n",
    "    # start date\n",
    "    start_date = (datetime.strptime(end_date, '%Y-%m-%d').date() -\n",
    "                  timedelta(weeks=weeks)).strftime('%Y-%m-%d')\n",
    "\n",
    "    # (1) proceed filtering: a duration of a period of time\n",
    "    # 期間條件\n",
    "    period_condition = (df.date >= start_date) & (df.date <= end_date)\n",
    "\n",
    "    # (2) proceed filtering: news category\n",
    "    # 新聞類別條件\n",
    "    if (cate == \"全部\"):\n",
    "        condition = period_condition  # \"全部\"類別不必過濾新聞種類\n",
    "    else:\n",
    "        # category新聞類別條件\n",
    "        condition = period_condition & (df.category == cate)\n",
    "\n",
    "    # (3) proceed filtering: news category\n",
    "    # and or 條件\n",
    "    if (cond == 'and'):\n",
    "        # query keywords condition使用者輸入關鍵字條件and\n",
    "        condition = condition & df.content.apply(lambda text: all(\n",
    "            (qk in text) for qk in user_keywords))  # 寫法:all()\n",
    "    elif (cond == 'or'):\n",
    "        # query keywords condition使用者輸入關鍵字條件\n",
    "        condition = condition & df.content.apply(lambda text: any(\n",
    "            (qk in text) for qk in user_keywords))  # 寫法:any()\n",
    "    # condiction is a list of True or False boolean value\n",
    "    df_query = df[condition]\n",
    "\n",
    "    return df_query\n",
    "\n",
    "\n",
    "# get titles and links from k pieces of news \n",
    "def get_title_link_topk(df_query, k=25):\n",
    "    items = []\n",
    "    for i in range( len(df_query[0:k]) ): # show only 10 news\n",
    "        category = df_query.iloc[i]['category']\n",
    "        title = df_query.iloc[i]['title']\n",
    "        link = df_query.iloc[i]['link']\n",
    "        photo_link = df_query.iloc[i]['photo_link']\n",
    "        # if photo_link value is NaN, replace it with empty string \n",
    "        if pd.isna(photo_link):\n",
    "            photo_link=''\n",
    "        \n",
    "        item_info = {\n",
    "            'category': category, \n",
    "            'title': title, \n",
    "            'link': link, \n",
    "            'photo_link': photo_link\n",
    "        }\n",
    "\n",
    "        items.append(item_info)\n",
    "    return items \n",
    "\n",
    "# Get related keywords by counting the top keywords of each news.\n",
    "# Notice:  do not name function as  \"get_related_keys\",\n",
    "# because this name is used in Django\n",
    "def get_related_word_clouddata(df_query):\n",
    "\n",
    "    # wf_pairs = get_related_words(df_query)\n",
    "    # prepare wf pairs \n",
    "    counter=Counter()\n",
    "    for idx in range(len(df_query)):\n",
    "        pair_dict = dict(eval(df_query.iloc[idx].top_key_freq))\n",
    "        counter += Counter(pair_dict)\n",
    "    wf_pairs = counter.most_common(20) #return list format\n",
    "\n",
    "    # cloud chart data\n",
    "    # the minimum and maximum frequency of top words\n",
    "    min_ = wf_pairs[-1][1]  # the last line is smaller\n",
    "    max_ = wf_pairs[0][1]\n",
    "    # text size based on the value of word frequency for drawing cloud chart\n",
    "    textSizeMin = 20\n",
    "    textSizeMax = 120\n",
    "    # Scaling frequency value into an interval of from 20 to 120.\n",
    "    clouddata = [{'text': w, 'size': int(textSizeMin + (f - min_) / (max_ - min_) * (textSizeMax - textSizeMin))}\n",
    "                 for w, f in wf_pairs]\n",
    "\n",
    "    return   wf_pairs, clouddata \n",
    "\n",
    "\n",
    "# Step1: split paragraphs in text 先將文章切成一個段落一個段落\n",
    "def cut_paragraph(text):\n",
    "    paragraphs = text.split('。')  # 遇到句號就切開\n",
    "    #paragraphs = re.split('。', text) # 遇到句號就切開\n",
    "    #paragraphs = re.split('[。！!？?]', text) # 遇到句號(也納入問號、驚嘆號、分號等)就切開\n",
    "    paragraphs = list(filter(None, paragraphs))\n",
    "    return paragraphs\n",
    "\n",
    "# Step2: Select all paragraphs where multiple keywords occur.\n",
    "\n",
    "\n",
    "def get_same_para(df_query, user_keywords, cond, k=30):\n",
    "    same_para = []\n",
    "    for text in df_query.content:\n",
    "        #print(text)\n",
    "        paragraphs = cut_paragraph(text)\n",
    "        for para in paragraphs:\n",
    "            para += \"。\"\n",
    "            if cond == 'and':\n",
    "                if all([re.search(kw, para) for kw in user_keywords]):\n",
    "                    same_para.append(para)\n",
    "            elif cond == 'or':\n",
    "                if any([re.search(kw, para) for kw in user_keywords]):\n",
    "                    same_para.append(para)\n",
    "    return same_para[0:k]\n",
    "\n",
    "\n",
    "    \n",
    "print(\"app_user_keyword_association was loaded!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For reference"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# A more complex way to split paragraphs\n",
    "# reference: https://blog.csdn.net/blmoistawinde/article/details/82379256\n",
    "# cut paragraghes from a news 切開文章段落\n",
    "def cut_paragraph(para):\n",
    "    para = re.sub('([。！？\\?])([^”’])', r\"\\1\\n\\2\", para)  # 单字符断句符\n",
    "    para = re.sub('(\\.{6})([^”’])', r\"\\1\\n\\2\", para)  # 英文省略号\n",
    "    para = re.sub('(\\…{2})([^”’])', r\"\\1\\n\\2\", para)  # 中文省略号\n",
    "    para = re.sub('([。！？\\?][”’])([^，。！？\\?])', r'\\1\\n\\2', para)\n",
    "    # 如果雙引號前有終止符，那麼雙引號才是句子的終點，把分句符\\n放到雙引號後，注意前面的幾句都小心保留了雙引號\n",
    "    para = para.rstrip()  # 段尾如果有多余的\\n就去掉它\n",
    "    # 分号忽略不计，破折号、英文双引号等同样忽略\n",
    "    return para.split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai23",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "toc-autonumbering": true,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
