{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CKIP Neural Chinese Word Segmentation, POS Tagging, and NER\n",
    "\n",
    "台灣人之光:Ckiplab中研院斷詞Python套件\n",
    "\n",
    "CHINESE KNOWLEDGE AND INFORMATION PROCESSING (詞庫小組)(助研究員馬偉雲)\t\n",
    "\n",
    "中研院資訊所、語言所於民國七十五年成立一個跨所合作的中文計算語言研究小組，共同合作建構中文自然語言處理的資源與研究環境，為國內外中文自然語言處理及其相關研究提供基本的研究資料與知識架構。代表性研究成果包括中文詞知識庫、語料庫及中文處理技術等。網際網路產生大量資訊，但缺乏有效的自動化分析方法及技術足以快速處理。為了達到智慧型的資訊處理，知識為本的訊息處理成為目前研究的核心焦點，本計劃進行五個主要研究方向：深度學習、知識表達、自然語言理解、知識擷取、聊天機器人。\n",
    "\n",
    "[Github](https://github.com/ckiplab/ckip-transformers)\n",
    "\n",
    "[Official website官網](https://ckip.iis.sinica.edu.tw/project/coreference/)\n",
    "\n",
    "[What can ckiplab NLP do? Let's take a look.](https://ckip.iis.sinica.edu.tw/service/corenlp/)\n",
    "\n",
    "![](https://ckip.iis.sinica.edu.tw/images/home/ckip.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ckiplab transformers model for tokenization\n",
    "    變形金剛模型\n",
    "\n",
    "        The package also provide the following NLP tools.\n",
    "        我們的套件也提供了以下的自然語言處理工具。\n",
    "        (WS) Word Segmentation 斷詞\n",
    "        (POS) Part-of-Speech Tagging 詞性標記\n",
    "        (NER) Named Entity Recognition 實體辨識\n",
    "        \n",
    "        Installation\n",
    "        pip install -U ckip-transformers\n",
    "\n",
    "        Requirements:\n",
    "\n",
    "        Python 3.6+\n",
    "        PyTorch 1.5+\n",
    "        HuggingFace Transformers 3.5+\n",
    "\n",
    "        https://github.com/ckiplab/ckip-transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install ckip-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ckip-transformers in c:\\users\\user\\anaconda3\\envs\\ai23\\lib\\site-packages (0.3.4)\n",
      "Requirement already satisfied: torch>=1.5.0 in c:\\users\\user\\anaconda3\\envs\\ai23\\lib\\site-packages (from ckip-transformers) (2.5.1+cu118)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\user\\anaconda3\\envs\\ai23\\lib\\site-packages (from ckip-transformers) (4.67.1)\n",
      "Requirement already satisfied: transformers>=3.5.0 in c:\\users\\user\\anaconda3\\envs\\ai23\\lib\\site-packages (from ckip-transformers) (4.49.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\user\\anaconda3\\envs\\ai23\\lib\\site-packages (from torch>=1.5.0->ckip-transformers) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\user\\anaconda3\\envs\\ai23\\lib\\site-packages (from torch>=1.5.0->ckip-transformers) (4.12.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\user\\anaconda3\\envs\\ai23\\lib\\site-packages (from torch>=1.5.0->ckip-transformers) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\user\\anaconda3\\envs\\ai23\\lib\\site-packages (from torch>=1.5.0->ckip-transformers) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\user\\anaconda3\\envs\\ai23\\lib\\site-packages (from torch>=1.5.0->ckip-transformers) (2024.9.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\user\\anaconda3\\envs\\ai23\\lib\\site-packages (from torch>=1.5.0->ckip-transformers) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\user\\anaconda3\\envs\\ai23\\lib\\site-packages (from sympy==1.13.1->torch>=1.5.0->ckip-transformers) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\anaconda3\\envs\\ai23\\lib\\site-packages (from tqdm>=4.27->ckip-transformers) (0.4.6)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in c:\\users\\user\\anaconda3\\envs\\ai23\\lib\\site-packages (from transformers>=3.5.0->ckip-transformers) (0.27.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\user\\anaconda3\\envs\\ai23\\lib\\site-packages (from transformers>=3.5.0->ckip-transformers) (2.1.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\user\\anaconda3\\envs\\ai23\\lib\\site-packages (from transformers>=3.5.0->ckip-transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\user\\anaconda3\\envs\\ai23\\lib\\site-packages (from transformers>=3.5.0->ckip-transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\user\\anaconda3\\envs\\ai23\\lib\\site-packages (from transformers>=3.5.0->ckip-transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in c:\\users\\user\\anaconda3\\envs\\ai23\\lib\\site-packages (from transformers>=3.5.0->ckip-transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\user\\anaconda3\\envs\\ai23\\lib\\site-packages (from transformers>=3.5.0->ckip-transformers) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\user\\anaconda3\\envs\\ai23\\lib\\site-packages (from transformers>=3.5.0->ckip-transformers) (0.4.5)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\user\\anaconda3\\envs\\ai23\\lib\\site-packages (from jinja2->torch>=1.5.0->ckip-transformers) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\user\\anaconda3\\envs\\ai23\\lib\\site-packages (from requests->transformers>=3.5.0->ckip-transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\anaconda3\\envs\\ai23\\lib\\site-packages (from requests->transformers>=3.5.0->ckip-transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\user\\anaconda3\\envs\\ai23\\lib\\site-packages (from requests->transformers>=3.5.0->ckip-transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\anaconda3\\envs\\ai23\\lib\\site-packages (from requests->transformers>=3.5.0->ckip-transformers) (2024.12.14)\n"
     ]
    }
   ],
   "source": [
    "!pip install -U ckip-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pytorch\n",
      "  Using cached pytorch-1.0.2.tar.gz (689 bytes)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Building wheels for collected packages: pytorch\n",
      "  Building wheel for pytorch (setup.py): started\n",
      "  Building wheel for pytorch (setup.py): finished with status 'error'\n",
      "  Running setup.py clean for pytorch\n",
      "Failed to build pytorch\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  × python setup.py bdist_wheel did not run successfully.\n",
      "  │ exit code: 1\n",
      "  ╰─> [6 lines of output]\n",
      "      Traceback (most recent call last):\n",
      "        File \"<string>\", line 2, in <module>\n",
      "        File \"<pip-setuptools-caller>\", line 34, in <module>\n",
      "        File \"C:\\Users\\User\\AppData\\Local\\Temp\\pip-install-vhf88vwk\\pytorch_7beaa58609d24b01a3a84cee22f35e0f\\setup.py\", line 15, in <module>\n",
      "          raise Exception(message)\n",
      "      Exception: You tried to install \"pytorch\". The package named for PyTorch is \"torch\"\n",
      "      [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "  ERROR: Failed building wheel for pytorch\n",
      "ERROR: ERROR: Failed to build installable wheels for some pyproject.toml based projects (pytorch)\n"
     ]
    }
   ],
   "source": [
    "pip install pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\user\\anaconda3\\envs\\ai23\\lib\\site-packages (2.19.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\user\\anaconda3\\envs\\ai23\\lib\\site-packages (from tensorflow) (1.4.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\user\\anaconda3\\envs\\ai23\\lib\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\user\\anaconda3\\envs\\ai23\\lib\\site-packages (from tensorflow) (25.2.10)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\user\\anaconda3\\envs\\ai23\\lib\\site-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\user\\anaconda3\\envs\\ai23\\lib\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\user\\anaconda3\\envs\\ai23\\lib\\site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\user\\anaconda3\\envs\\ai23\\lib\\site-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\user\\anaconda3\\envs\\ai23\\lib\\site-packages (from tensorflow) (24.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in c:\\users\\user\\anaconda3\\envs\\ai23\\lib\\site-packages (from tensorflow) (5.29.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\user\\anaconda3\\envs\\ai23\\lib\\site-packages (from tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\user\\anaconda3\\envs\\ai23\\lib\\site-packages (from tensorflow) (75.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\user\\anaconda3\\envs\\ai23\\lib\\site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\user\\anaconda3\\envs\\ai23\\lib\\site-packages (from tensorflow) (2.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\user\\anaconda3\\envs\\ai23\\lib\\site-packages (from tensorflow) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\user\\anaconda3\\envs\\ai23\\lib\\site-packages (from tensorflow) (1.17.2)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\user\\anaconda3\\envs\\ai23\\lib\\site-packages (from tensorflow) (1.70.0)\n",
      "Requirement already satisfied: tensorboard~=2.19.0 in c:\\users\\user\\anaconda3\\envs\\ai23\\lib\\site-packages (from tensorflow) (2.19.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in c:\\users\\user\\anaconda3\\envs\\ai23\\lib\\site-packages (from tensorflow) (3.9.0)\n",
      "Requirement already satisfied: numpy<2.2.0,>=1.26.0 in c:\\users\\user\\anaconda3\\envs\\ai23\\lib\\site-packages (from tensorflow) (2.1.3)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\user\\anaconda3\\envs\\ai23\\lib\\site-packages (from tensorflow) (3.13.0)\n",
      "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in c:\\users\\user\\anaconda3\\envs\\ai23\\lib\\site-packages (from tensorflow) (0.5.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\user\\anaconda3\\envs\\ai23\\lib\\site-packages (from tensorflow) (0.31.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\user\\anaconda3\\envs\\ai23\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.44.0)\n",
      "Requirement already satisfied: rich in c:\\users\\user\\anaconda3\\envs\\ai23\\lib\\site-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
      "Requirement already satisfied: namex in c:\\users\\user\\anaconda3\\envs\\ai23\\lib\\site-packages (from keras>=3.5.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in c:\\users\\user\\anaconda3\\envs\\ai23\\lib\\site-packages (from keras>=3.5.0->tensorflow) (0.14.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\user\\anaconda3\\envs\\ai23\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\anaconda3\\envs\\ai23\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\user\\anaconda3\\envs\\ai23\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\anaconda3\\envs\\ai23\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2024.12.14)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\user\\anaconda3\\envs\\ai23\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\user\\anaconda3\\envs\\ai23\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\user\\anaconda3\\envs\\ai23\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow) (3.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\user\\anaconda3\\envs\\ai23\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (2.1.3)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\user\\anaconda3\\envs\\ai23\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\user\\anaconda3\\envs\\ai23\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\user\\anaconda3\\envs\\ai23\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -U tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\user\\anaconda3\\envs\\ai23\\lib\\site-packages (4.47.1)\n",
      "Collecting transformers\n",
      "  Downloading transformers-4.49.0-py3-none-any.whl.metadata (44 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\user\\anaconda3\\envs\\ai23\\lib\\site-packages (from transformers) (3.16.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in c:\\users\\user\\anaconda3\\envs\\ai23\\lib\\site-packages (from transformers) (0.27.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\user\\anaconda3\\envs\\ai23\\lib\\site-packages (from transformers) (2.2.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\user\\anaconda3\\envs\\ai23\\lib\\site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\user\\anaconda3\\envs\\ai23\\lib\\site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\user\\anaconda3\\envs\\ai23\\lib\\site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in c:\\users\\user\\anaconda3\\envs\\ai23\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\user\\anaconda3\\envs\\ai23\\lib\\site-packages (from transformers) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\user\\anaconda3\\envs\\ai23\\lib\\site-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\user\\anaconda3\\envs\\ai23\\lib\\site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\user\\anaconda3\\envs\\ai23\\lib\\site-packages (from huggingface-hub<1.0,>=0.26.0->transformers) (2024.9.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\user\\anaconda3\\envs\\ai23\\lib\\site-packages (from huggingface-hub<1.0,>=0.26.0->transformers) (4.12.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\anaconda3\\envs\\ai23\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\user\\anaconda3\\envs\\ai23\\lib\\site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\anaconda3\\envs\\ai23\\lib\\site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\user\\anaconda3\\envs\\ai23\\lib\\site-packages (from requests->transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\anaconda3\\envs\\ai23\\lib\\site-packages (from requests->transformers) (2024.12.14)\n",
      "Downloading transformers-4.49.0-py3-none-any.whl (10.0 MB)\n",
      "   ---------------------------------------- 0.0/10.0 MB ? eta -:--:--\n",
      "   ----- ---------------------------------- 1.3/10.0 MB 11.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  10.0/10.0 MB 32.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 10.0/10.0 MB 29.6 MB/s eta 0:00:00\n",
      "Installing collected packages: transformers\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.47.1\n",
      "    Uninstalling transformers-4.47.1:\n",
      "      Successfully uninstalled transformers-4.47.1\n",
      "Successfully installed transformers-4.49.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Ensure transformers library is installed\n",
    "%pip install -U transformers"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load tokenization models\n",
    "     ws斷詞, pos詞性標示, ner實體名稱(命名)辨識之模型，\n",
    "\n",
    "\n",
    "    CKIP Transformers v.s. Monpa & Jeiba\n",
    "    \n",
    "    Tool\tWS (F1)\tPOS (Acc)\tWS+POS (F1)\tNER (F1)\n",
    "    CKIP BERT Base\t97.60%\t95.67%\t94.19%\t81.18%\n",
    "    CKIP ALBERT Base\t97.33%\t95.30%\t93.52%\t79.47%\n",
    "    CKIP BERT Tiny\t96.98%\t95.08%\t93.13%\t74.20%\n",
    "    CKIP ALBERT Tiny\t96.66%\t94.48%\t92.25%\t71.17%\n",
    "                    \n",
    "    Monpa†\t92.58%\t--\t83.88%\t--\n",
    "    Jeiba\t81.18%\t--\t--\t--\n",
    "\n",
    "    https://github.com/ckiplab/ckip-transformers\n",
    "\n",
    "    # Initialize drivers\n",
    "    ws_driver  = CkipWordSegmenter(model=\"bert-base\")\n",
    "    pos_driver = CkipPosTagger(model=\"bert-base\")\n",
    "    ner_driver = CkipNerChunker(model=\"bert-base\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ckip_transformers.nlp import CkipWordSegmenter, CkipPosTagger, CkipNerChunker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f30d2ffe98e745dfa6a7df834756794b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/15.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ad3f75071184a57a0ade0a66b1a518c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/301 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "510ad52df8de489d8432e9738618bea5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/110k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d7f6431cb16421fb089c344483f9755",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44e68187296e44cd8a7c7493efb1d7b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/15.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf5cf47ada23410a9a2af6aee0e9af64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/2.89k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14ba2efd99e6459a9b652d2005ddff32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/16.0M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18b6c7cfe20c4deeb7815a7442c8e806",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/301 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5cb5c8bbe164dcf8889c4a2db53e9b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/110k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "378ad9f8900045b596d7c88858038abf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e312fe71513f4d5b932cf763d2992bb2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/16.0M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed23ad64098b431cadeed7edd2856e30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/3.74k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d453aab810447f58d803c5e38cab032",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/16.0M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19e58ed672fa4fe08427717d31a510fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/301 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7c66f4094ef4f89918e118f32598cc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/110k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bfb906a31844940b531d9ed4ad567fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/16.0M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac7be0f5055145029f0ec851ddd00285",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Initialize drivers\n",
    "# It takes time to download ckiplab models\n",
    "\n",
    "\n",
    "\n",
    "# default參數是model=\"bert-base\"\n",
    "# ws = CkipWordSegmenter() \n",
    "# pos = CkipPosTagger()\n",
    "# ner = CkipNerChunker()\n",
    "\n",
    "# model=\"albert-tiny\" 模型小，斷詞速度比較快，犧牲一些精確度\n",
    "ws = CkipWordSegmenter(model=\"albert-tiny\") \n",
    "pos = CkipPosTagger(model=\"albert-tiny\")\n",
    "ner = CkipNerChunker(model=\"albert-tiny\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Usage example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 1002.70it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.42it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['傅達仁', '今', '將', '執行', '安樂死']]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ws([\"傅達仁今將執行安樂死\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 68.83it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['Nb', 'Nd', 'D', 'VC', 'VH']]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos([['傅達仁', '今', '將', '執行', '安樂死']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 71.09it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[NerToken(word='傅達仁', ner='PERSON', idx=(0, 3))]]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner([\"傅達仁今將執行安樂死\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process multiple documents\n",
    "\n",
    "we must put documents in a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# two ducuments\n",
    "docs = [\"高科大、文藻外語大學與故宮自2016年12月攜手辦理人才培育計畫，培養學生擔任中英文導覽及參與故宮南院的實作服務。\",\"美國參議院針對今天總統布什所提名的勞工部長趙小蘭展開認可聽證會，預料她將會很順利通過參議院支持。\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 2/2 [00:00<00:00, 1998.72it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 29.21it/s]\n",
      "Tokenization: 100%|██████████| 2/2 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 48.72it/s]\n",
      "Tokenization: 100%|██████████| 2/2 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 53.65it/s]\n"
     ]
    }
   ],
   "source": [
    "words = ws(docs)\n",
    "pos_tag = pos(words)\n",
    "ner_result = ner(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['高科大',\n",
       "  '、',\n",
       "  '文藻',\n",
       "  '外語',\n",
       "  '大學',\n",
       "  '與',\n",
       "  '故宮',\n",
       "  '自',\n",
       "  '2016年',\n",
       "  '12月',\n",
       "  '攜手',\n",
       "  '辦理',\n",
       "  '人才',\n",
       "  '培育',\n",
       "  '計畫',\n",
       "  '，',\n",
       "  '培養',\n",
       "  '學生',\n",
       "  '擔任',\n",
       "  '中英文',\n",
       "  '導覽',\n",
       "  '及',\n",
       "  '參與',\n",
       "  '故宮',\n",
       "  '南',\n",
       "  '院',\n",
       "  '的',\n",
       "  '實作',\n",
       "  '服務',\n",
       "  '。'],\n",
       " ['美國',\n",
       "  '參議院',\n",
       "  '針對',\n",
       "  '今天',\n",
       "  '總統',\n",
       "  '布什',\n",
       "  '所',\n",
       "  '提名',\n",
       "  '的',\n",
       "  '勞工部長',\n",
       "  '趙小蘭',\n",
       "  '展開',\n",
       "  '認可',\n",
       "  '聽證會',\n",
       "  '，',\n",
       "  '預料',\n",
       "  '她',\n",
       "  '將',\n",
       "  '會',\n",
       "  '很',\n",
       "  '順利',\n",
       "  '通過',\n",
       "  '參議院',\n",
       "  '支持',\n",
       "  '。']]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Nc',\n",
       "  'PAUSECATEGORY',\n",
       "  'Nb',\n",
       "  'Na',\n",
       "  'Nc',\n",
       "  'Caa',\n",
       "  'Nc',\n",
       "  'P',\n",
       "  'Neu',\n",
       "  'Neu',\n",
       "  'D',\n",
       "  'VC',\n",
       "  'Na',\n",
       "  'VC',\n",
       "  'Na',\n",
       "  'COMMACATEGORY',\n",
       "  'VC',\n",
       "  'Na',\n",
       "  'VG',\n",
       "  'Na',\n",
       "  'VC',\n",
       "  'Caa',\n",
       "  'VC',\n",
       "  'Nc',\n",
       "  'Ncd',\n",
       "  'Nc',\n",
       "  'DE',\n",
       "  'Nv',\n",
       "  'VC',\n",
       "  'PERIODCATEGORY'],\n",
       " ['Nc',\n",
       "  'Nc',\n",
       "  'P',\n",
       "  'Nd',\n",
       "  'Na',\n",
       "  'Nb',\n",
       "  'D',\n",
       "  'VC',\n",
       "  'DE',\n",
       "  'Na',\n",
       "  'Nb',\n",
       "  'VC',\n",
       "  'VC',\n",
       "  'Na',\n",
       "  'COMMACATEGORY',\n",
       "  'VE',\n",
       "  'Nh',\n",
       "  'D',\n",
       "  'D',\n",
       "  'Dfa',\n",
       "  'VH',\n",
       "  'VC',\n",
       "  'Nc',\n",
       "  'VC',\n",
       "  'PERIODCATEGORY']]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[NerToken(word='2016年12月', ner='DATE', idx=(14, 22)),\n",
       "  NerToken(word='中英文', ner='LANGUAGE', idx=(39, 42)),\n",
       "  NerToken(word='故宮南院', ner='FAC', idx=(47, 51))],\n",
       " [NerToken(word='美國參議院', ner='ORG', idx=(0, 5)),\n",
       "  NerToken(word='今天', ner='LOC', idx=(7, 9)),\n",
       "  NerToken(word='布什', ner='PERSON', idx=(11, 13)),\n",
       "  NerToken(word='勞工部長', ner='ORG', idx=(17, 21)),\n",
       "  NerToken(word='趙小蘭', ner='PERSON', idx=(21, 24)),\n",
       "  NerToken(word='認可聽證會', ner='EVENT', idx=(26, 31)),\n",
       "  NerToken(word='參議院', ner='ORG', idx=(42, 45))]]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# POS Tagging詞性標註"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Name\tDescription\n",
    "A\t非謂形容詞\n",
    "Caa\t對等連接詞\n",
    "Cab\t連接詞，如：等等\n",
    "Cba\t連接詞，如：的話\n",
    "Cbb\t關聯連接詞\n",
    "D\t副詞\n",
    "Da\t數量副詞\n",
    "Dfa\t動詞前程度副詞\n",
    "Dfb\t動詞後程度副詞\n",
    "Di\t時態標記\n",
    "Dk\t句副詞\n",
    "DM\t定量式\n",
    "I\t感嘆詞\n",
    "Na\t普通名詞\n",
    "Nb\t專有名詞\n",
    "Nc\t地方詞\n",
    "Ncd\t位置詞\n",
    "Nd\t時間詞\n",
    "Nep\t指代定詞\n",
    "Neqa\t數量定詞\n",
    "Neqb\t後置數量定詞\n",
    "Nes\t特指定詞\n",
    "Neu\t數詞定詞\n",
    "Nf\t量詞\n",
    "Ng\t後置詞\n",
    "Nh\t代名詞\n",
    "Nv\t名物化動詞\n",
    "P\t介詞\n",
    "T\t語助詞\n",
    "VA\t動作不及物動詞\n",
    "VAC\t動作使動動詞\n",
    "VB\t動作類及物動詞\n",
    "VC\t動作及物動詞\n",
    "VCL\t動作接地方賓語動詞\n",
    "VD\t雙賓動詞\n",
    "VF\t動作謂賓動詞\n",
    "VE\t動作句賓動詞\n",
    "VG\t分類動詞\n",
    "VH\t狀態不及物動詞\n",
    "VHC\t狀態使動動詞\n",
    "VI\t狀態類及物動詞\n",
    "VJ\t狀態及物動詞\n",
    "VK\t狀態句賓動詞\n",
    "VL\t狀態謂賓動詞\n",
    "V_2\t有\n",
    "DE\t的之得地\n",
    "SHI\t是\n",
    "FW\t外文\n",
    "COLONCATEGORY\t冒號\n",
    "COMMACATEGORY\t逗號\n",
    "DASHCATEGORY\t破折號\n",
    "DOTCATEGORY\t點號\n",
    "ETCCATEGORY\t刪節號\n",
    "EXCLAMATIONCATEGORY\t驚嘆號\n",
    "PARENTHESISCATEGORY\t括號\n",
    "PAUSECATEGORY\t頓號\n",
    "PERIODCATEGORY\t句號\n",
    "QUESTIONCATEGORY\t問號\n",
    "SEMICOLONCATEGORY\t分號\n",
    "SPCHANGECATEGORY\t雙直線\n",
    "WHITESPACE\t空白"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 204.96it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['Nb', 'Nd', 'D', 'VC', 'VH']]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos([['傅達仁', '今', '將', '執行', '安樂死']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 5/5 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 179.00it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['Nb', 'Nb', 'Na'], ['Nd'], ['P'], ['VC', 'VC'], ['Na', 'VH', 'VH']]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# wrong format 這樣給資料結果是不對的，會切成一個字一個字\n",
    "pos(['傅達仁', '今', '將', '執行', '安樂死'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = [\"高科大、文藻外語大學與故宮自2016年12月攜手辦理人才培育計畫，培養學生擔任中英文導覽及參與故宮南院的實作服務。\"]\n",
    "\n",
    "# docs = [\"美國參議院針對今天總統布什所提名的勞工部長趙小蘭展開認可聽證會，預料她將會很順利通過參議院支持。\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 145.55it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 166.69it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['Nc',\n",
       "  'PAUSECATEGORY',\n",
       "  'Nb',\n",
       "  'Na',\n",
       "  'Nc',\n",
       "  'Caa',\n",
       "  'Nc',\n",
       "  'P',\n",
       "  'Neu',\n",
       "  'Neu',\n",
       "  'D',\n",
       "  'VC',\n",
       "  'Na',\n",
       "  'VC',\n",
       "  'Na',\n",
       "  'COMMACATEGORY',\n",
       "  'VC',\n",
       "  'Na',\n",
       "  'VG',\n",
       "  'Na',\n",
       "  'VC',\n",
       "  'Caa',\n",
       "  'VC',\n",
       "  'Nc',\n",
       "  'Ncd',\n",
       "  'Nc',\n",
       "  'DE',\n",
       "  'Nv',\n",
       "  'VC',\n",
       "  'PERIODCATEGORY']]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = ws(docs)\n",
    "pos(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['高科大',\n",
       "  '、',\n",
       "  '文藻',\n",
       "  '外語',\n",
       "  '大學',\n",
       "  '與',\n",
       "  '故宮',\n",
       "  '自',\n",
       "  '2016年',\n",
       "  '12月',\n",
       "  '攜手',\n",
       "  '辦理',\n",
       "  '人才',\n",
       "  '培育',\n",
       "  '計畫',\n",
       "  '，',\n",
       "  '培養',\n",
       "  '學生',\n",
       "  '擔任',\n",
       "  '中英文',\n",
       "  '導覽',\n",
       "  '及',\n",
       "  '參與',\n",
       "  '故宮',\n",
       "  '南',\n",
       "  '院',\n",
       "  '的',\n",
       "  '實作',\n",
       "  '服務',\n",
       "  '。']]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## combine word and pos (將詞與其詞性 搭配一起顯示)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = [\"高科大、文藻外語大學與故宮自2016年12月攜手辦理人才培育計畫，培養學生擔任中英文導覽及參與故宮南院的實作服務。\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 125.08it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 83.35it/s]\n"
     ]
    }
   ],
   "source": [
    "words = ws(docs)\n",
    "pos_tag = pos(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pos_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pos_tag[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_pos_pair=[]\n",
    "for i in range(len(words)):\n",
    "    word_pos_pair.append(list(zip( words[i], pos_tag[i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('高科大', 'Nc'),\n",
       "  ('、', 'PAUSECATEGORY'),\n",
       "  ('文藻', 'Nb'),\n",
       "  ('外語', 'Na'),\n",
       "  ('大學', 'Nc'),\n",
       "  ('與', 'Caa'),\n",
       "  ('故宮', 'Nc'),\n",
       "  ('自', 'P'),\n",
       "  ('2016年', 'Neu'),\n",
       "  ('12月', 'Neu'),\n",
       "  ('攜手', 'D'),\n",
       "  ('辦理', 'VC'),\n",
       "  ('人才', 'Na'),\n",
       "  ('培育', 'VC'),\n",
       "  ('計畫', 'Na'),\n",
       "  ('，', 'COMMACATEGORY'),\n",
       "  ('培養', 'VC'),\n",
       "  ('學生', 'Na'),\n",
       "  ('擔任', 'VG'),\n",
       "  ('中英文', 'Na'),\n",
       "  ('導覽', 'VC'),\n",
       "  ('及', 'Caa'),\n",
       "  ('參與', 'VC'),\n",
       "  ('故宮', 'Nc'),\n",
       "  ('南', 'Ncd'),\n",
       "  ('院', 'Nc'),\n",
       "  ('的', 'DE'),\n",
       "  ('實作', 'Nv'),\n",
       "  ('服務', 'VC'),\n",
       "  ('。', 'PERIODCATEGORY')]]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_pos_pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('高科大', 'Nc'),\n",
       "  ('、', 'PAUSECATEGORY'),\n",
       "  ('文藻', 'Nb'),\n",
       "  ('外語', 'Na'),\n",
       "  ('大學', 'Nc'),\n",
       "  ('與', 'Caa'),\n",
       "  ('故宮', 'Nc'),\n",
       "  ('自', 'P'),\n",
       "  ('2016年', 'Neu'),\n",
       "  ('12月', 'Neu'),\n",
       "  ('攜手', 'D'),\n",
       "  ('辦理', 'VC'),\n",
       "  ('人才', 'Na'),\n",
       "  ('培育', 'VC'),\n",
       "  ('計畫', 'Na'),\n",
       "  ('，', 'COMMACATEGORY'),\n",
       "  ('培養', 'VC'),\n",
       "  ('學生', 'Na'),\n",
       "  ('擔任', 'VG'),\n",
       "  ('中英文', 'Na'),\n",
       "  ('導覽', 'VC'),\n",
       "  ('及', 'Caa'),\n",
       "  ('參與', 'VC'),\n",
       "  ('故宮', 'Nc'),\n",
       "  ('南', 'Ncd'),\n",
       "  ('院', 'Nc'),\n",
       "  ('的', 'DE'),\n",
       "  ('實作', 'Nv'),\n",
       "  ('服務', 'VC'),\n",
       "  ('。', 'PERIODCATEGORY')]]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# same result with one line \n",
    "[ list(zip(w,p)) for w,p in zip(words, pos_tag)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(['高科大',\n",
       "   '、',\n",
       "   '文藻',\n",
       "   '外語',\n",
       "   '大學',\n",
       "   '與',\n",
       "   '故宮',\n",
       "   '自',\n",
       "   '2016年',\n",
       "   '12月',\n",
       "   '攜手',\n",
       "   '辦理',\n",
       "   '人才',\n",
       "   '培育',\n",
       "   '計畫',\n",
       "   '，',\n",
       "   '培養',\n",
       "   '學生',\n",
       "   '擔任',\n",
       "   '中英文',\n",
       "   '導覽',\n",
       "   '及',\n",
       "   '參與',\n",
       "   '故宮',\n",
       "   '南',\n",
       "   '院',\n",
       "   '的',\n",
       "   '實作',\n",
       "   '服務',\n",
       "   '。'],\n",
       "  ['Nc',\n",
       "   'PAUSECATEGORY',\n",
       "   'Nb',\n",
       "   'Na',\n",
       "   'Nc',\n",
       "   'Caa',\n",
       "   'Nc',\n",
       "   'P',\n",
       "   'Neu',\n",
       "   'Neu',\n",
       "   'D',\n",
       "   'VC',\n",
       "   'Na',\n",
       "   'VC',\n",
       "   'Na',\n",
       "   'COMMACATEGORY',\n",
       "   'VC',\n",
       "   'Na',\n",
       "   'VG',\n",
       "   'Na',\n",
       "   'VC',\n",
       "   'Caa',\n",
       "   'VC',\n",
       "   'Nc',\n",
       "   'Ncd',\n",
       "   'Nc',\n",
       "   'DE',\n",
       "   'Nv',\n",
       "   'VC',\n",
       "   'PERIODCATEGORY'])]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip(words, pos_tag))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['高科大',\n",
       "  '、',\n",
       "  '文藻',\n",
       "  '外語',\n",
       "  '大學',\n",
       "  '與',\n",
       "  '故宮',\n",
       "  '自',\n",
       "  '2016年',\n",
       "  '12月',\n",
       "  '攜手',\n",
       "  '辦理',\n",
       "  '人才',\n",
       "  '培育',\n",
       "  '計畫',\n",
       "  '，',\n",
       "  '培養',\n",
       "  '學生',\n",
       "  '擔任',\n",
       "  '中英文',\n",
       "  '導覽',\n",
       "  '及',\n",
       "  '參與',\n",
       "  '故宮',\n",
       "  '南',\n",
       "  '院',\n",
       "  '的',\n",
       "  '實作',\n",
       "  '服務',\n",
       "  '。'],\n",
       " ['Nc',\n",
       "  'PAUSECATEGORY',\n",
       "  'Nb',\n",
       "  'Na',\n",
       "  'Nc',\n",
       "  'Caa',\n",
       "  'Nc',\n",
       "  'P',\n",
       "  'Neu',\n",
       "  'Neu',\n",
       "  'D',\n",
       "  'VC',\n",
       "  'Na',\n",
       "  'VC',\n",
       "  'Na',\n",
       "  'COMMACATEGORY',\n",
       "  'VC',\n",
       "  'Na',\n",
       "  'VG',\n",
       "  'Na',\n",
       "  'VC',\n",
       "  'Caa',\n",
       "  'VC',\n",
       "  'Nc',\n",
       "  'Ncd',\n",
       "  'Nc',\n",
       "  'DE',\n",
       "  'Nv',\n",
       "  'VC',\n",
       "  'PERIODCATEGORY'])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip(words, pos_tag))[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NER (named entity recognition)實體命名辨識\n",
    "* 例如：人名、地名、組織名，在生醫領域中也可能是藥品名、分子式等等。NER 讓機器能自動找尋文本中提到的我們感興趣的實體，例如公眾人物等，並加以分析，其產出亦作為人工智慧理解自然語言的重要資訊。\n",
    "* 小明PERSON昨天DATE在中研院FAC附近買了五CARDINAL顆蘋果。"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Name\tDescription\n",
    "CARDINAL\t數字\n",
    "DATE\t日期\n",
    "EVENT\t事件\n",
    "FAC\t設施\n",
    "GPE\t行政區\n",
    "LANGUAGE\t語言\n",
    "LAW\t法律\n",
    "LOC\t地理區\n",
    "MONEY\t金錢\n",
    "NORP\t民族、宗教、政治團體\n",
    "ORDINAL\t序數\n",
    "ORG\t組織\n",
    "PERCENT\t百分比率\n",
    "PERSON\t人物\n",
    "PRODUCT\t產品\n",
    "QUANTITY\t數量\n",
    "TIME\t時間\n",
    "WORK_OF_ART\t作品"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = [\"高科大、文藻外語大學與故宮自2016年12月攜手辦理人才培育計畫，培養學生擔任中英文導覽及參與故宮南院的實作服務。\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 100.00it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[NerToken(word='2016年12月', ner='DATE', idx=(14, 22)),\n",
       "  NerToken(word='中英文', ner='LANGUAGE', idx=(39, 42)),\n",
       "  NerToken(word='故宮南院', ner='FAC', idx=(47, 51))]]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai23",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
